<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: How To Live In A Simulation</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: How To Live In A Simulation">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: How To Live In A Simulation</h1>
<!-- received="Thu Mar 15 14:38:03 2001" -->
<!-- isoreceived="20010315213803" -->
<!-- sent="Thu, 15 Mar 2001 16:38:13 -0500" -->
<!-- isosent="20010315213813" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: How To Live In A Simulation" -->
<!-- id="3AB13645.9B678040@pobox.com" -->
<!-- inreplyto="Pine.UW2.4.20.0103151130360.7469-100000@www.aeiveos.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20How%20To%20Live%20In%20A%20Simulation&In-Reply-To=&lt;3AB13645.9B678040@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Mar 15 2001 - 14:38:13 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0673.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Kurzweil's new Singularity/AI page"</a>
<li><strong>Previous message:</strong> <a href="0671.html">J. R. Molloy: "How To Live In A Real World"</a>
<li><strong>In reply to:</strong> <a href="0657.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0688.html">Gordon Worley: "Sysop vs. Liberty (was Re: How To Live In A Simulation)"</a>
<li><strong>Reply:</strong> <a href="0688.html">Gordon Worley: "Sysop vs. Liberty (was Re: How To Live In A Simulation)"</a>
<li><strong>Reply:</strong> <a href="0695.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0720.html">Jim Fehlinger: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#672">[ date ]</a>
<a href="index.html#672">[ thread ]</a>
<a href="subject.html#672">[ subject ]</a>
<a href="author.html#672">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Robert J. Bradbury&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Reliberion's Prince of Darkness (aka Eliezer wrote):
</em><br>
<p>...why?
<br>
<p><em>&gt; &gt; If this is a simulation, I don't expect that I have much free will.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Of course you have free will, what would be the point of a simulation
</em><br>
<em>&gt; if you didn't?  [Now of course, if you are a zombie in the simulation
</em><br>
<em>&gt; in which *I* have the free will, then you don't...]
</em><br>
<p>It's a historical simulation of Transition celebrity Eliezer Yudkowsky, of
<br>
course.  A lot of post-Singularity still-human individuals ran it, more so
<br>
as Eliezer is one of the few (historical) personalities that can be run in
<br>
a totally immersive, non-knowing simulation without violating citizenship
<br>
rights... though it does have a certain effect on your personality...
<br>
<p>Not that *I'm* volunteering, but I can easily see myself reaching that
<br>
conclusion (even pre-Singularity), and that might be enough under the
<br>
rules.
<br>
<p>You can watch the 24-hour Buffy channel; you can live in an immersive
<br>
Buffyverse Matrix filled with totally realistic personalities for all
<br>
other sentients; you can adopt a Buffy outlook and personality; you can
<br>
assimilate Buffy's historical memories (as revealed by Joss Whedon); you
<br>
can shove your memories of the real world into the back of your mind; you
<br>
can damp down the cognitive processes whereby your knowledge of the
<br>
unreality of your world interferes with the emotional impact - but you
<br>
still need enough memory of the external world to give your continuous
<br>
informed consent, because a pure vanilla Buffy wouldn't consent to being
<br>
stuck in her horrible world... or choose to load your &quot;real&quot; memories back
<br>
in after leaving it.
<br>
<p>You can only undergo a totally unknowing sim experience if the sim
<br>
personality is such as to (a) consent and (b) be willing to load your true
<br>
memories back in afterwards.  So it's more than usually plausible that
<br>
*I'm* a simulation, not just because of my potential celebrity, but
<br>
because Eliezer Yudkowsky is one of the few historical personalities who
<br>
might be willing to do that - exist and hurt and be effectively
<br>
annihilated at the end - *if* there were a really strong reason, something
<br>
to be gained under my/his morality; because right now, at least, I assign
<br>
my own life the same value I would assign anyone else's, and I'd need a
<br>
good reason before I'd allow myself to be hurt.  In the apparent/original
<br>
world, the Singularity can take precedence over my welfare; in a world
<br>
where there's no Singularity to be gained, I/he/we would need a pretty
<br>
good reason to consent to the recreation of negative experiences, even if
<br>
it's consent-in-potentia.
<br>
<p>But again, in that case, all you guys out there are zombies, and I'm
<br>
writing this email because it was in the historical record - so why dwell
<br>
on it?
<br>
<p><em>&gt; How do you even know or enforce what someone else does with their
</em><br>
<em>&gt; computronium?
</em><br>
<p>You own and control your own computronium, but you control it through the
<br>
Sysop API, and trying to violate citizenship rights will result in an API
<br>
error.  If we're in a sim with no citizenship rights, then we are so
<br>
totally, utterly screwed that there is really very little that I can think
<br>
of to do about it.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0673.html">Eugene.Leitl@lrz.uni-muenchen.de: "Re: Kurzweil's new Singularity/AI page"</a>
<li><strong>Previous message:</strong> <a href="0671.html">J. R. Molloy: "How To Live In A Real World"</a>
<li><strong>In reply to:</strong> <a href="0657.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0688.html">Gordon Worley: "Sysop vs. Liberty (was Re: How To Live In A Simulation)"</a>
<li><strong>Reply:</strong> <a href="0688.html">Gordon Worley: "Sysop vs. Liberty (was Re: How To Live In A Simulation)"</a>
<li><strong>Reply:</strong> <a href="0695.html">Robert J. Bradbury: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0720.html">Jim Fehlinger: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#672">[ date ]</a>
<a href="index.html#672">[ thread ]</a>
<a href="subject.html#672">[ subject ]</a>
<a href="author.html#672">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:59:40 MDT</em>
</em>
</small>
</body>
</html>
