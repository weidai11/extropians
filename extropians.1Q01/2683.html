<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: AI: Autonomous Mental Development by Robots and	Ani</title>
<meta name="Author" content="Eugene.Leitl@lrz.uni-muenchen.de (Eugene.Leitl@lrz.uni-muenchen.de)">
<meta name="Subject" content="AI: Autonomous Mental Development by Robots and	Animals">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>AI: Autonomous Mental Development by Robots and	Animals</h1>
<!-- received="Sun Jan 28 13:01:30 2001" -->
<!-- isoreceived="20010128200130" -->
<!-- sent="Sun, 28 Jan 2001 20:59:31 +0100" -->
<!-- isosent="20010128195931" -->
<!-- name="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="AI: Autonomous Mental Development by Robots and	Animals" -->
<!-- id="3A747A23.DB24B2E1@lrz.uni-muenchen.de" -->
<strong>From:</strong> <a href="mailto:Eugene.Leitl@lrz.uni-muenchen.de?Subject=Re:%20AI:%20Autonomous%20Mental%20Development%20by%20Robots%20and	Animals&In-Reply-To=&lt;3A747A23.DB24B2E1@lrz.uni-muenchen.de&gt;"><em>Eugene.Leitl@lrz.uni-muenchen.de</em></a><br>
<strong>Date:</strong> Sun Jan 28 2001 - 12:59:31 MST
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2684.html">John Marlow: "Re: selling an idea"</a>
<li><strong>Previous message:</strong> <a href="2682.html">Spike Jones: "Re: selling an idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2683">[ date ]</a>
<a href="index.html#2683">[ thread ]</a>
<a href="subject.html#2683">[ subject ]</a>
<a href="author.html#2683">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
<a href="http://www.sciencemag.org/cgi/content/full/291/5504/599">http://www.sciencemag.org/cgi/content/full/291/5504/599</a>
<br>
<p>ARTIFICIAL INTELLIGENCE: Autonomous Mental Development by Robots and
<br>
Animals
<br>
<p>Juyang Weng, * James McClelland, Alex Pentland, Olaf Sporns, Ida
<br>
Stockman, Mriganka Sur, Esther Thelen
<br>
<p>How does one create an intelligent machine? This problem has proven
<br>
difficult. Over the past several decades, scientists have taken one of
<br>
three approaches: In the first, which is knowledge-based, an
<br>
intelligent machine in a laboratory is directly programmed to perform
<br>
a given task. In a second, learning-based approach, a computer is
<br>
&quot;spoon-fed&quot; human-edited sensory data while the machine is controlled
<br>
by a task-specific learning program. Finally, by a &quot;genetic search,&quot;
<br>
robots have evolved through generations by the principle of survival
<br>
of the fittest, mostly in a computer-simulated virtual world. Although
<br>
notable, none of these is powerful enough to lead to machines having
<br>
the complex, diverse, and highly integrated capabilities of an adult
<br>
brain, such as vision, speech, and language. Nevertheless, these
<br>
traditional approaches have served as the incubator for the birth and
<br>
growth of a new direction for machine intelligence: autonomous mental
<br>
development. As Kuhn wrote (1), &quot;Failure of existing rules is the
<br>
prelude to a search for new ones.&quot;
<br>
<p>A Definition
<br>
What is autonomous mental development? With time, a brainlike natural
<br>
or an artificial embodied system, under the control of its intrinsic
<br>
developmental program (coded in the genes or artificially designed)
<br>
develops mental capabilities through autonomous real-time interactions
<br>
with its environments (including its own internal environment and
<br>
components) by using its own sensors and effectors. Traditionally, a
<br>
machine is not autonomous when it develops its skills, but a human is
<br>
autonomous throughout its lifelong mental development.
<br>
<p>Recent advances in neuroscience illustrate this principle. For
<br>
example, if the optic nerves originating from the eyes of an animal
<br>
(i.e., a ferret) are connected into the auditory pathway early in
<br>
life, the auditory cortex gradually takes on a representation that is
<br>
normally found in the visual cortex (2). Further, the &quot;rewired&quot;
<br>
animals successfully learn to perform vision tasks with the auditory
<br>
cortex. This discovery suggests that the cortex is governed by
<br>
developmental principles that work for both visual and auditory
<br>
signals. In another example, the developmental program of the monkey
<br>
brain dynamically selects sensory input, (e.g., three fingers instead
<br>
of one, as normal), according to the actual sensory signal that is
<br>
received, and this selection process is active throughout adulthood
<br>
(3).
<br>
<p>Computational modeling of human neural and cognitive development has
<br>
just started to be a subject of study (4, 5). To be successful,
<br>
mainstream cognitive psychology needs to advance from explaining
<br>
psychological phenomena in specific controlled settings toward
<br>
deriving underlying computational principles of mental development
<br>
that are applicable to general settings. Such computational studies
<br>
are necessary for understanding of mind.
<br>
<p>The idea of mental development is also applicable to machines, but it
<br>
has not received serious attention in the artificial intelligence
<br>
community. In the past, many believed that hand programming alone or
<br>
task-specific machine learning could be sufficient for constructing an
<br>
intelligent machine. Nevertheless, recently it was pointed out that to
<br>
be truly intelligent, machines need autonomous mental development
<br>
(6). (See the figure, below.)
<br>
<p><p><p>Growing up. Mental development is realized through autonomous
<br>
interactions with the real physical world.
<br>
<p><p>Manual Versus Autonomous Development
<br>
The traditional manual development paradigm can be described as follows:
<br>
 Start with a task, understood by the human engineer (not the machine).
<br>
 Design a task-specific representation.
<br>
 Program for the specific task using the representation.
<br>
 Run the program on the machine.
<br>
<p>If, during program execution, sensory data are used to modify the
<br>
parameters of the above predesigned task-specific representation, we
<br>
say that this is machine learning. In this traditional paradigm, a
<br>
machine cannot do anything beyond the predesigned representation. In
<br>
fact, it does not even &quot;know&quot; what it is doing. All it does is run the
<br>
program.
<br>
<p>The autonomous development paradigm for constructing developmental robots is as
<br>
follows:
<br>
 Design a body according to the robot's ecological working conditions (e.g., on land or
<br>
under water).
<br>
 Design a developmental program.
<br>
 At &quot;birth,&quot; the robot starts to run the developmental program.
<br>
 To develop its mind, humans mentally &quot;raise&quot; the developmental robot by interacting
<br>
with it in real time.
<br>
<p>According to this paradigm, robots should be designed to go through a
<br>
long period of autonomous mental development, from &quot;infancy&quot; to
<br>
&quot;adulthood.&quot; The essence of mental development is to enable robots to
<br>
autonomously &quot;live&quot; in the world and to become smart on their own,
<br>
with some supervision by humans.
<br>
<p>Our human genetic program has evolved to use our body
<br>
well. Analogously, the developmental programs for robots should also
<br>
be body-specific, or specific to robot &quot;species,&quot; as are traditional
<br>
programs.
<br>
<p>However, a developmental program for developing a robot mind must have
<br>
other properties (see the table) that set it apart from all the
<br>
traditional programs: It cannot be task-specific, because the tasks
<br>
are unknown at the time of programming, and the robots should be
<br>
enabled to do any job that we can teach them. A human can potentially
<br>
learn to take any job--as a computer scientist, an artist, or a
<br>
gymnast. The programmer who writes a developmental program for a robot
<br>
does not know what tasks the future robot owners will be teaching
<br>
it. Furthermore, a developmental program for robots must be able to
<br>
generate automatically representations for unknown knowledge and
<br>
skills. Like humans and animals, the robots must learn in real time
<br>
while performing &quot;on the fly.&quot; A mental developmental process is also
<br>
an open-ended cumulative process: A robot cannot learn complex skills
<br>
successfully without first learning necessary simpler skills, e.g.,
<br>
without learning how to hold a pen, the robot will not be able to
<br>
learn how to write.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;DIFFERENCES BETWEEN ROBOT PROGRAMS
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Properties
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traditional
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Developmental
<br>
&nbsp;&nbsp;Not task specific
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes
<br>
&nbsp;&nbsp;Tasks are unknown
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes
<br>
&nbsp;&nbsp;Generates a representation
<br>
&nbsp;&nbsp;of an unknown task
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes
<br>
&nbsp;&nbsp;Animal-like online learning
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes
<br>
&nbsp;&nbsp;Open-ended learning
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes
<br>
<p><p><p>Early Prototypes
<br>
Early prototypes of developmental robots include Darwin V (7) and SAIL
<br>
(6, 8, shown below), developed independently around the same time but
<br>
with very different goals.  Darwin V was designed to provide a
<br>
concrete example for how the computational weights of neural circuits
<br>
are determined by the behavioral and environmental interactions of an
<br>
autonomous device. Through real-world interactions with physical
<br>
objects, Darwin V developed a capability for position-invariant object
<br>
recognition, allowing a transition from simple behaviors to more
<br>
complex ones.
<br>
<p><p><p>CREDIT: J. WENG
<br>
<p><p>The goal of the SAIL developmental robot was to generate automatically
<br>
representations and architectures for scaling up to more complex
<br>
capabilities in unconstrained, unknown human environments. For
<br>
example, after a human pushes the SAIL robot &quot;for a walk&quot; along
<br>
corridors of a large building, SAIL can navigate on its own in similar
<br>
environments while &quot;seeing&quot; with its two video cameras. After humans
<br>
show toys to SAIL and help SAIL's hand to reach them, SAIL can pay
<br>
attention to these toys, recognize them, and reach them too. To allow
<br>
SAIL to learn autonomously, the human robot-sitter lets it explore the
<br>
world on its own, but encourages and discourages behaviors by pressing
<br>
its &quot;good&quot; button or &quot;bad&quot; button. Responses invariant to
<br>
task-unrelated factors are achieved through automatically deriving
<br>
discriminating features. A real-time speed is reached by
<br>
self-organizing large memory in a coarse-to-fine way (9). These and
<br>
other examples that aim at automation of learning [e.g., (10)] have
<br>
demonstrated robotic capabilities that have not been achieved before
<br>
or that are very difficult to achieve with traditional methods.
<br>
<p>The Future
<br>
Computational studies of autonomous mental development should be
<br>
significantly more tractable than traditional task-specific approaches
<br>
to constructing intelligent machines and to understanding natural
<br>
intelligence, because the developmental principles are more general in
<br>
nature and are simpler than the world around us. For example, the
<br>
visual world seen by our eyes is very complex. The light that falls on
<br>
a particular pixel in a camera depends on many factors--lighting,
<br>
object shape, object surface reflectance, viewing geometry, camera
<br>
type, and so on. The developmental principles capture major
<br>
statistical characteristics from visual signals (e.g., the mean and
<br>
major directions of signal distribution), rather than every aspect of
<br>
the world that gives rise to these signals. A task-specific
<br>
programmer, in contrast, must study aspects of the world around the
<br>
specific task to be learned; this becomes intractable if such a task,
<br>
such as vision, speech, or language, requires too many diverse
<br>
capabilities.
<br>
<p>This new field will provide a unified framework for many cognitive
<br>
capabilities--vision, audition, taction, language, planning,
<br>
decision-making, and task execution. The sharing of common
<br>
developmental principles by visual and auditory sensing modalities, as
<br>
recent neuroscience studies have demonstrated, will encourage
<br>
scientists to further discover underlying developmental principles
<br>
that are shared, not only by different sensing and effector
<br>
modalities, but also by different aspects of higher brain
<br>
functions. Developmental robots can &quot;live&quot; with us and become smarter
<br>
autonomously, under our human supervision.
<br>
<p>It is important for neuroscientists and psychologists to discover
<br>
computational principles of mental development. And in fact,
<br>
developmental mechanisms are quantitative in nature at the level of
<br>
neural cells. The precision of knowledge required to verify these
<br>
principles on robots will improve our chances of answering some major
<br>
open questions in cognitive science, such as how the human brain
<br>
develops a sense of the world around it.
<br>
<p>Advances in creating robots capable of autonomous mental development
<br>
are likely to improve the quality of human life. When robots can
<br>
autonomously develop capabilities, such as vision, speech, and
<br>
language, humans will be able to train them using their own
<br>
communication modes. Developmental robots will learn to perform dull
<br>
and repetitive tasks that humans do not like to do, e.g., carrying out
<br>
missions in demanding environments such as undersea and space
<br>
exploration and cleaning up nuclear waste.
<br>
<p>We believe that there is a need for a special program for funding
<br>
support of this new field of autonomous mental development. This
<br>
program should encourage collaboration among fields that study human
<br>
and machine mental development. Biologically motivated mental
<br>
development methods for robots and computational modeling of animal
<br>
mental development should be especially encouraged. There is also a
<br>
need for a multidisciplinary forum for exchanging the latest research
<br>
findings in this new field, similar to the Workshop on Development and
<br>
Learning funded by NSF and Defense Advanced Research Projects Agency
<br>
held at Michigan State University (11). We anticipate a potentially
<br>
large impact on science, society, and the economy by advances in this
<br>
new direction.
<br>
<p>References and Notes
<br>
<p>&nbsp;&nbsp;1.T. S. Kuhn, The Structure of Scientific Revolution (Univ. of Chicago Press,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Chicago, 3rd ed., 1996), p. 68. 
<br>
&nbsp;&nbsp;2.L. von Melchner, S. L. Pallas, M. Sur, Nature 404, 871 (2000). 
<br>
&nbsp;&nbsp;3.X. Wang, M. M. Merzenich, K. Sameshima, W. M. Jenkins, Nature 378, 13 (1995). 
<br>
&nbsp;&nbsp;4.J. L. Elman et al., Rethinking Innateness: A Connectionist Perspective on
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Development (MIT Press, Cambridge, MA, 1997). 
<br>
&nbsp;&nbsp;5.E. Thelen, E. G. Schoner, C Scheier, L. B. Smith, Behav. Brain Sci., in press. 
<br>
&nbsp;&nbsp;6.J. Weng, in Learning in Computer Vision and Beyond: Development in Visual
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Communication and Image Processing, C. W. Chen, Y. Q. Zhang, Eds. (Marcel
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dekker, New York, 1998) (Michigan State Univ. tech. rep. CPS 96-60, East
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lansing, MI, 1996). 
<br>
&nbsp;&nbsp;7.N. Almassy, G. M. Edelman, O. Sporns, Cereb. Cortex 8, 346 (1998). 
<br>
&nbsp;&nbsp;8.J. Weng, W. S. Hwang, Y. Zhang, C. Evans, in Proceedings of the 2nd
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;International Symposium on Humanoid Robots, 8 to 9 October 1999, Tokyo, pp.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;57-64. 
<br>
&nbsp;&nbsp;9.W. S. Hwang, J. Weng, IEE Trans. Pattern Anal. Machine Intell. 22, 11 (2000). 
<br>
&nbsp;10.D. Roy, B. Schiele, A. Pentland, in Workshop on Integrating Speech and Image
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Understanding, Proceedings of an International Conference on Computer Vision,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;21 September 1999, Corfu, Greece (IEEE Press, New York, 1999). 
<br>
&nbsp;11.Proceedings of Workshop on Development and Learning, 5 to 7 April 2000,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Michigan State University, East Lansing, MI. www.cse.msu.edu/dl/. 
<br>
<p><p>J. Weng is at the Department of Computer Science and Engineering,
<br>
Michigan State University, East Lansing, MI 48824, USA. J. McClelland
<br>
is at the Center for the Neural Basis of Cognition, Carnegie Mellon
<br>
University, Pittsburgh, PA 15213, USA. A.  Pentland is at The Media
<br>
Laboratory, Massachusetts Institute of Technology, Cambridge, MA
<br>
02139, USA. O. Sporns and E. Thelen are at the Department of
<br>
Psychology, Indiana University, Bloomington, IN 47405,
<br>
USA. I. Stockman is at the Department of Audiology and Speech
<br>
Sciences, Michigan State University, East Lansing, MI 48824,
<br>
USA. M. Sur is at the Department of Brain and Cognitive Sciences,
<br>
Massachusetts Institute of Technology, Cambridge, MA 02139, USA.
<br>
<p>*To whom correspondence should be addressed. E-mail: <a href="mailto:weng@cse.msu.edu?Subject=Re:%20AI:%20Autonomous%20Mental%20Development%20by%20Robots%20and	Animals&In-Reply-To=&lt;3A747A23.DB24B2E1@lrz.uni-muenchen.de&gt;">weng@cse.msu.edu</a>
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2684.html">John Marlow: "Re: selling an idea"</a>
<li><strong>Previous message:</strong> <a href="2682.html">Spike Jones: "Re: selling an idea"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2683">[ date ]</a>
<a href="index.html#2683">[ thread ]</a>
<a href="subject.html#2683">[ subject ]</a>
<a href="author.html#2683">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:56:26 MDT</em>
</em>
</small>
</body>
</html>
