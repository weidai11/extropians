<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>Extropians: Re: How Extropians Live Their Lives was: Optimism</title>
<meta name="Author" content="Bryan Moss (bryan.moss@dsl.pipex.com)">
<meta name="Subject" content="Re: How Extropians Live Their Lives was: Optimism">
<meta name="Date" content="2003-07-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How Extropians Live Their Lives was: Optimism</h1>
<!-- received="Sat Jul 19 20:04:10 2003" -->
<!-- isoreceived="20030720020410" -->
<!-- sent="Sun, 20 Jul 2003 02:42:58 +0100" -->
<!-- isosent="20030720014258" -->
<!-- name="Bryan Moss" -->
<!-- email="bryan.moss@dsl.pipex.com" -->
<!-- subject="Re: How Extropians Live Their Lives was: Optimism" -->
<!-- id="009701c34e60$44a6e0c0$49f55651@bryan" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Pine.WNT.4.50.0307181737320.1896-100000@dfab.na.plumtree.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bryan Moss (<a href="mailto:bryan.moss@dsl.pipex.com?Subject=Re:%20How%20Extropians%20Live%20Their%20Lives%20was:%20Optimism"><em>bryan.moss@dsl.pipex.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 19 2003 - 19:42:58 MDT
</p>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11680.html">scerir: "Re: Damien's e-book"</a>
<ul>
<li><strong>Previous message:</strong> <a href="11678.html">Harvey Newstrom: "RE: flame wars"</a>
<li><strong>In reply to:</strong> <a href="11630.html">Dan Fabulich: "How Extropians Live Their Lives was: Optimism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11687.html">Bryan Moss: "A note on bioethics."</a>
<li><strong>Reply:</strong> <a href="11687.html">Bryan Moss: "A note on bioethics."</a>
<li><strong>Reply:</strong> <a href="11691.html">Rafal Smigrodzki: "Re: How Extropians Live Their Lives was: Optimism"</a>
<li><strong>Reply:</strong> <a href="11692.html">Damien Broderick: "Bryan Moss's recent posts"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11679">[ date ]</a>
<a href="index.html#11679">[ thread ]</a>
<a href="subject.html#11679">[ subject ]</a>
<a href="author.html#11679">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Dan Fabulich wrote:
<br>
<p><em>&gt; Any suggestions?
</em><br>
<p>I thought I'd already made one!  My contention, far from wanting to
<br>
immobolise everyone to action (which would be hypocritical for I, like you,
<br>
am an armchair extropian), is that immobility is inherent in our
<br>
philosophy, and we need first to purge our theory.  I think Extropy is a
<br>
child of the computer age and has inherited certain features, one of which
<br>
is Inevitability.  The computer revolution was couched in very teleological
<br>
terms; the great Telos of this revolution was Intelligence.  A lot of good,
<br>
honest work in computing goes ignored because the next product iteration (or
<br>
the one after that) might be closer to this ultimate end.  We talk about it
<br>
in terms of progress, but that's not really true at all.  Computer progress
<br>
has been fairly deterministic, both in terms of hardware and software.  What
<br>
people are talking about when they say &quot;I'm not working on Y because Z is
<br>
probably just around the corner&quot; is progress-towards.
<br>
<p>Whenever we talk about Artificial Intelligence we assume this Inevitability;
<br>
the debates about thinking machines have always focused on whether a
<br>
thinking machine can be really said to be thinking, rather than whether one
<br>
can be created.  This has lead to some strange conventions on both sides of
<br>
the debate.  If I argue against AI with a sort of negative proof, where I
<br>
show, that should an AI be created, it wouldn't be capable of genuine
<br>
thought, I give no accurate picture of when or in what form the inability to
<br>
create an AI will manifest itself.  Will we keep progressing towards the
<br>
goal of a thinking machine only to realise at the last minute that it isn't
<br>
thinking at all?  I think most people that make these sort of arguments
<br>
against AI, although they speak in very abstract terms, zombies and such,
<br>
expect the lack of genuine, conscious thought to manifest itself in some
<br>
way, and, if they considered it, they'd probably expect AI research to not
<br>
get off the ground at all.  On the otherside of the debate, there's this
<br>
uncritical approach to method; the researchers hold that a thinking machine
<br>
will be capable of genuine thought, and that seems to be enough for them.
<br>
If it's possible for a computer to be intelligent, then we'll just sit down
<br>
and program it.  We're intelligent, right?  Who better to do it!
<br>
<p>The general argument I want to make is that our ultratechnologies are a
<br>
product of this ominous big-I Inevitability, rather than vice versa.  We can
<br>
remove them and be free from this choice of extremes you describe.
<br>
<p>The fact remains that there is no reason to think the (or a) Singularity
<br>
inevitable; none, nada, zero, zelch, zip.  It's a prediction based on two
<br>
things: (1) Moore's Law; (2) some rough calculations of the processing power
<br>
of the human brain.  The first is a product of smoking crack, the second the
<br>
result of speculation.  There's no such obvious correlation between the
<br>
brain, that lump of electro-chemical gunk, and the microprocessor.  The
<br>
numbers we use to predict the Rupture (Singularity) or decide how many
<br>
&quot;potential lives&quot; are lost by not colonising space or nuking North Korea
<br>
(for fucks sake) are rough, back of the envelope calculations by a
<br>
roboticist that make some massive, sweeping assumptions about the brain.
<br>
When someone expresses the opinion that, perhaps, the brain isn't easily
<br>
simulated, they're usually met with, &quot;I doubt anything quantum mechanical is
<br>
going on,&quot; which forgets that there's no simple correlation between
<br>
classical physics and classical computers.  An actual simulation of the
<br>
brain, its biological and chemical processes, is most likely impractical.  A
<br>
&quot;simulation&quot; of thought processes is pure pseudo-science, as is any claim to
<br>
a &quot;general intelligence.&quot;  You can argue that not everything that happens in
<br>
the brain (physically speaking) plays a functional role in thought, and
<br>
that's fair (depending on your criteria), but if you start arguing that you
<br>
know what does and does not play functional roles, in any strong sense,
<br>
you're most likely being disingenuous.  My point here is not to say that
<br>
these things are impossible in any absolute sense, my point is to show that
<br>
they are not inevitable (or necessarily even plausible).  The inevitability
<br>
enters elsewhere, in the sense of this general Telos, our futurism, which we
<br>
organise these ideas around.  It is not genuine.
<br>
<p>The ultratechnologies are the biggest, most obviously damaging problems in
<br>
our philosophy.  The smaller problems are best demonstrated through
<br>
language.  This word &quot;immortal,&quot; for example.  I think it's with a certain
<br>
glee that we use this word that, to the majority of people, has religious
<br>
connotations.  We seem to enjoy co-opting ideas from the religious and
<br>
reconstituting them as something very secular.  Personally I think we'd do
<br>
better to leave the immortality to the spirits.  When you say &quot;I'm an
<br>
immortalist&quot; the rest of the world hears &quot;I'm an arrogant prick.&quot;  I am not
<br>
an immortalist, I am not overcoming death, I am not angry at a world that
<br>
would let millions of people die every year due to old age.  I recognise a
<br>
certain event in history, a certain truth, about our nature, about our
<br>
bodies.  I'd position this around the flourishing of cellular biology, the
<br>
invention of the defibrillator, etc; those discoveries and technologies that
<br>
did not so much afford the opportunity to overcome death as to put the
<br>
status of death into question.  The ideas we need to get out to the world
<br>
are: that the status of the body has changed, we are no longer whole, the
<br>
process of life is a continuing process of creation and destruction; and
<br>
that the status of death as a genuine event, as the placeable end to your
<br>
life, has been called into question.  I think it's wrong to reconstitute
<br>
death as a process; putrefaction is a process, death is cultural, not
<br>
bodily.  That's our lesson: the event of death is something cultural, some
<br>
malleable, and is subject to cultural difference.  Rather than harking on
<br>
about the loss of lives to aging, which marks us out as kooks to most
<br>
people, we need to present ourselves as what we are: a subculture, whose
<br>
values are as valid as traditional values and adoptable by anyone.  Perhaps
<br>
one day we'll be more than a subculture, but for now this is what we are.
<br>
<p>One of the general points I'm trying to make here is that we need to foster
<br>
a sense of humility.  Another example through language: &quot;genetic
<br>
engineering.&quot;  Never has such an unfortunate term been coined.  For some of
<br>
us, it's a very practical, very concrete thing, and the word serves that
<br>
well.  What's more practical and concrete than engineering?  The term
<br>
&quot;genetic engineering&quot; lends genes a solidity; we can move them, build with
<br>
them, engineer.  But both &quot;genetic&quot; and &quot;engineering&quot; carry mutually
<br>
supporting alternative intepretations.  &quot;Genetic&quot; can mean hereditary,
<br>
natural, fundamental.  To &quot;engineer&quot; can mean to manipulate, to control, in
<br>
the historical sense, the social sense, the behavioural sense.  This use
<br>
of &quot;engineer&quot; carries with it the connotation that approaching something as
<br>
mechanical is dehumanising.  But again, we revel in it.  Researchers
<br>
gleefully make references to the &quot;book of life,&quot; DNA is written in &quot;God's
<br>
hand,&quot; we're unravelling Nature itself.  This is a turning point in history,
<br>
a great event, we have read the human genome.  The reality is both more
<br>
mundane and much more interesting.  DNA is not the &quot;book of life,&quot; it's not
<br>
the static tome that revels our innermost being, it's dynamic, it's not the
<br>
description of life but life its very self.  Again, we need to get this out
<br>
to people: we're no longer whole, we're teeming with life.  I remember the
<br>
first time I read Engines of Creation; what struck me most was not the
<br>
wonderful vision of the future, or the vast potential of nanotechnology, but
<br>
the description of the machinary already at work in our bodies.  I think one
<br>
of the stumbling blocks for people with genetic engineering is that they
<br>
still think of themselves as an impenetrable unity, genetics seems like
<br>
something occult, when really it's business as usual.  The desire to shock
<br>
and amaze is innate, people love to tell stories, so we tend to avoid
<br>
demythologising these issues.  Instead, we think we'll convince them with a
<br>
*different* amazing story, the amazing story of how their lives will change
<br>
for the better.  But the truth is, these stories are of the same kind.
<br>
<p>It's almost a cliché to say that our culture is one that's wary of &quot;grand
<br>
narratives,&quot; but we *are* just out of a century that is marked by the
<br>
atrocities committed under names such as National Socialism and Communism,
<br>
so it is perhaps a fair assessment.  I will suggest here that the
<br>
informational theoretical valuation of life, as expressed in Nick Bostrom's
<br>
paper and Robert's recent post, is as dangerous as the racial valuation that
<br>
led to the artocities committed under the name of Nazism.  People aren't
<br>
scared of science, they're scared of us: those who'll take science a step
<br>
too far.  When people express trepidation that they'll be &quot;reduced&quot; to their
<br>
DNA or to machines or whatever, we announce, again, with a certain glee,
<br>
that that is all we are.  &quot;What,&quot; we chuckle, &quot;you thought we had souls?  A
<br>
spirit?&quot;  But their fears are not so easily dismissed; they may often be
<br>
expressed in terms of the spiritual, the religious, the intuitive, things we
<br>
tend to deride, but they speak to a genuine fear: that human life will be
<br>
reduced to something only of economic value.  That human lives will be
<br>
ordered, their relative merits weighed, and some will be valued over others.
<br>
This is easily posited as a question of ethics, but I think that's a
<br>
mistake.  To solve this particular issue as a question of ethics, is to put
<br>
ethics before all else, a move I'm not fond of because I think it puts
<br>
knowledge, truth, etc, in too difficult a position.  It remains a question
<br>
of philosophy, which I would resolve with the following suggestion: human
<br>
life can only have a situated value, a value in relation to something.
<br>
Robert talks about triage, this is a definite situation.  &quot;Which one do we
<br>
treat first?&quot;  This is already something economical.  The flaw in Robert's
<br>
genocidal suggestion, I propose, is that it's too close to attributing
<br>
absolute value to human lives, which we can see in its invocation of the
<br>
awkward idea of &quot;potential people.&quot;  This is only a tentative suggestion
<br>
because it leaves open the problem of what constitues a situation, what
<br>
separates a situated valuation from an absolute, and these things need to be
<br>
clarified.  But, intuitively, it speaks to me: it's very easy to ask of
<br>
racism, for example, &quot;what makes race x better?&quot;  The answer is usually
<br>
given as a rather arbitrary list or an appeal to some absolute value: race x
<br>
is better because race x is race x.  Racists spend a lot of time looking for
<br>
ways to devalue other races, but ultimately this is just a way of expounding
<br>
on the supposed &quot;truth&quot; they already hold.  Also note that Robert's
<br>
suggestion is an argument along the same lines as the &quot;ethics first&quot;
<br>
solution.  &quot;If all human life is sacred,&quot; he asks, &quot;then isn't more human
<br>
life more sacred?  If destroying some human life will ultimate cause more
<br>
human life to flourish, isn't that okay?&quot;  We reply: &quot;No, all human life is
<br>
sacred!&quot;  There isn't a satisfactory ethical solution.
<br>
<p>My thesis, then, is that there's something rotten at the core of Extropy.
<br>
The reason you can't find a way to connect extropianism with practical
<br>
action in your life is that extropianism, as it stands now, is out of touch
<br>
with life generally.  It's exactly about inaction, futurism, Rupture, sit
<br>
tight and let technology take you for a ride.  This may not have been its
<br>
founder's intention and this may not be true of all its supporters, but
<br>
that's basically what we have.  We're a product of our time.  My interim
<br>
proposal is humility.  There's a lot to be done here and now, if you can
<br>
just bring it back into focus.  My long term proposal is reevaluation of our
<br>
entire philosophy or the establishment of something different.  To be
<br>
honest, the idea of activists for the future, which is what a pro-active
<br>
extropianism amounts to, is rather ridiculous.  This isn't a case of &quot;the
<br>
future will be great if you don't fuck it up.&quot;  It never was.  I don't think
<br>
even &quot;we can build a better tomorrow through hard work&quot; quite cuts it for
<br>
me, because it still contains the kernel of that futurism, that
<br>
Inevitability.  What would an extropianism without futurism be?  A stance on
<br>
technology, on humanity, on culture, on the body, but without the appeal to
<br>
a future, a telos, without the utopianism.  In a sense, it would embrace a
<br>
degree of uncertainty along with its humility.  I would hope too that it
<br>
would embrace a sense of its own limits, it own bounds.  To often we want
<br>
to pave over everything.  I still remember a particular suggestion, made by
<br>
Eliezer I think, that the Singularity is so Different that it reduces all
<br>
our cultural differences; these differences no longer matter in the shadow
<br>
of the Absolute Difference of the Singularity.  We see this again in
<br>
Robert's proposal, &quot;I mean really -- if a 1 cm^3 nanocomputer can support
<br>
100,000+ human minds our 'individuality' is probably overrated.&quot;  These
<br>
statements, always said with that same, certain glee, echo some of the worst
<br>
excesses of modernity.  I think there's some truth in much of contemporary
<br>
theory when it states that Western culture (which is now almost synonymous
<br>
with American culture), even its science and technology, is not a universal,
<br>
not progress per se, but just a particular expression of a particular
<br>
culture at a particular time.  I think they overstate the case; I think the
<br>
strongest case that can be made is that whether something is universal or
<br>
particular is undecidable, although both must exist, otherwise the
<br>
suggestion is too problematic (not that I agree with this either).  However,
<br>
even if the denial of the universal subject, of truth, of knowledge, etc,
<br>
takes things too far, we can still use this observation.  We can exercise a
<br>
certain caution when we talk of progress, of the developing world, etc, and
<br>
take care not to overstate *our* case.  Not everyone shares our values, not
<br>
everyone has to, and unless we find ourselves in a situation of relative
<br>
values, a conflict, we need not reduce others to valuation.
<br>
<p>So, what should we do, in terms of practical action?  I think, with a
<br>
certain humility, and *without* the sense of victimisation that comes from
<br>
(needlessly) setting ourselves so far apart from mainstream culture, a lot
<br>
of avenues start to open before us, our project becomes more manageable,
<br>
more real, our thought takes on human scales.  This is really what action
<br>
is: thought on a scale that leads to intervention.  The intervention itself
<br>
is usual immediate and obvious, it's usually clearly situated and well
<br>
bounded, it is (or can be) an extension of thought.  Examples might be
<br>
activism for the acceptance of genetically modified foods, education about
<br>
how death is an ambiguous event, countering the theses of people you
<br>
disagree with, etc.  Can you write a critical review of one of the recent
<br>
books on the dangers of biotechnology and life extension?  Get it published
<br>
somewhere prominent?  We need to get ideas out there, but they need to be
<br>
sociable ideas.  There's too much scoffing, outright dismissal, etc.  On a
<br>
smaller scale, being able to express your ideas in mixed company without
<br>
garnering looks of disgust is great goal to work towards.  But it's a goal
<br>
that requires humility (again) and respect; I'm not talking about marketing
<br>
or spin, I want to see extropianism embrace a genuine desire to be in the
<br>
world, this world, right now, enjoying the things everyone else enjoys.
<br>
<p>BM
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11680.html">scerir: "Re: Damien's e-book"</a>
<li><strong>Previous message:</strong> <a href="11678.html">Harvey Newstrom: "RE: flame wars"</a>
<li><strong>In reply to:</strong> <a href="11630.html">Dan Fabulich: "How Extropians Live Their Lives was: Optimism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11687.html">Bryan Moss: "A note on bioethics."</a>
<li><strong>Reply:</strong> <a href="11687.html">Bryan Moss: "A note on bioethics."</a>
<li><strong>Reply:</strong> <a href="11691.html">Rafal Smigrodzki: "Re: How Extropians Live Their Lives was: Optimism"</a>
<li><strong>Reply:</strong> <a href="11692.html">Damien Broderick: "Bryan Moss's recent posts"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11679">[ date ]</a>
<a href="index.html#11679">[ thread ]</a>
<a href="subject.html#11679">[ subject ]</a>
<a href="author.html#11679">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Sat Jul 19 2003 - 20:16:36 MDT
</em></small></p>
</body>
</html>
