<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Review of &quot;Open Your Eyes&quot;</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Review of &quot;Open Your Eyes&quot;">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Review of &quot;Open Your Eyes&quot;</h1>
<!-- received="Mon Sep 10 01:40:49 2001" -->
<!-- isoreceived="20010910074049" -->
<!-- sent="Mon, 10 Sep 2001 03:38:50 -0400" -->
<!-- isosent="20010910073850" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Review of &quot;Open Your Eyes&quot;" -->
<!-- id="3B9C6E0A.B5EEFD7@pobox.com" -->
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Review%20of%20&quot;Open%20Your%20Eyes&quot;&In-Reply-To=&lt;3B9C6E0A.B5EEFD7@pobox.com&gt;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Sep 10 2001 - 01:38:50 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5973.html">Samantha Atkins: "Re: Singularity: can't happen here"</a>
<li><strong>Previous message:</strong> <a href="5971.html">Samantha Atkins: "Re: Singularity: can't happen here"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5984.html">Technotranscendence: "Re: Review of &quot;Open Your Eyes&quot;"</a>
<li><strong>Reply:</strong> <a href="5984.html">Technotranscendence: "Re: Review of &quot;Open Your Eyes&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5972">[ date ]</a>
<a href="index.html#5972">[ thread ]</a>
<a href="subject.html#5972">[ subject ]</a>
<a href="author.html#5972">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
&quot;Open Your Eyes&quot;
<br>
<a href="http://www.amazon.com/exec/obidos/ASIN/B00005LZOD/singinst/">http://www.amazon.com/exec/obidos/ASIN/B00005LZOD/singinst/</a>
<br>
<p><p>NONSPOILER REVIEW:
<br>
<p><p>It is practically impossible to say *anything* about &quot;Open Your Eyes&quot;
<br>
without enormous spoilerage, so I'll keep the nonspoiler review short: 
<br>
Five stars, go watch it.  Currently &quot;Open Your Eyes&quot; is available in
<br>
Spanish with subtitles (the version I watched).  A remake of this movie,
<br>
&quot;Vanilla Sky&quot;, starring Tom Cruise, is supposed to be in theaters December
<br>
14th 2001.  If the remake is faithful to the original, and it doesn't win
<br>
the Hugo, then the Hugo doesn't deserve to exist.  If the remake is not
<br>
faithful to the original, I will discover the names of those responsible.
<br>
<p>(For those of you who saw &quot;The Others&quot;, this is by the same director. 
<br>
&quot;The Others&quot; was also a good movie, but not as good as this.)
<br>
<p><p><p><p><p><p>SEMISPOILER REVIEW:
<br>
<p><p><p><p><p><p>&quot;Open Your Eyes&quot; is carefully structured transhumanist science fiction
<br>
(unlike sloppily structured transhumanist science fiction, such as &quot;The
<br>
Matrix&quot;).  If &quot;The Matrix&quot; is a transhumanist action movie, then &quot;Open
<br>
Your Eyes&quot; is a transhumanist psychological thriller.  Throughout this
<br>
movie I had the interesting experience of repeatedly saying &quot;Could that be
<br>
- ?  Does that mean - ?  Nah, it couldn't possibly.  I'm just putting my
<br>
own Extropian-acclimated interpretation on it.  The director couldn't be
<br>
that smart.&quot;  And then it turns out that the director IS that smart.  As
<br>
someone who always expects Hollywood to screw up and dumb down whatever
<br>
they touch - and yes, this ultimately happened even to &quot;The Matrix&quot; - I
<br>
was pleasantly astonished by this movie.
<br>
<p>&quot;Open Your Eyes&quot;, and the forthcoming &quot;Vanilla Sky&quot; is very definitely an
<br>
instance of the mainstream creeping up on transhumanism.  Yet another
<br>
morsel of understanding that was formerly the sole province of a few
<br>
isolated mailing lists is about to be gulped down by the public at large.
<br>
<p><p><p><p><p><p><p><p>MASSIVE TOTAL SPOILER REVIEW:
<br>
<p><p><p><p><p><p><p><p>In the same sense that the sheer total giveaway of the Matrix is &quot;The main
<br>
character is living in a computer simulation run by AIs, and once awakened
<br>
by the resistance he is able to gain control of the simulation&quot;, the sheer
<br>
total giveaway of &quot;Open Your Eyes&quot; is &quot;The main character is in an
<br>
accident and has his face terribly disfigured until surgeons miraculously
<br>
repair it; it turns out, however, that he actually signed up for cryonics
<br>
after his accident, committed suicide, got cryonically frozen, was revived
<br>
150 years in the future, and is currently living out a fantasy dream in
<br>
which his face was repaired, but the dream has started to go wrong, and he
<br>
now needs to wake up.&quot;  (Note that &quot;Open Your Eyes&quot; was a 1997 movie,
<br>
giving it priority over &quot;The Matrix&quot;.)
<br>
<p>This movie, if the US remake is faithful to the original, will do for
<br>
cryonics what &quot;The Matrix&quot; did for the &quot;this world is a computer
<br>
simulation&quot; hypothesis.  I would say that the presentation is basically
<br>
fair to cryonics as described by its advocates.  Alcor will probably get a
<br>
ton of new inquiries when the US version, &quot;Vanilla Sky&quot; comes out.  If
<br>
Alcor doesn't know about &quot;Open Your Eyes&quot; and the forthcoming US version,
<br>
someone really ought to tell them NOW - although I would be surprised to
<br>
find Alcor innocent.  The name of the cryonics organization in the movie
<br>
is &quot;Life Extension&quot;, which is a pretty good match for &quot;Alcor Life
<br>
Extension Foundation&quot; if you ask me.
<br>
<p>I would rate this movie as SL3 rather than SL4, since it seems pretty
<br>
clear that the protagonist's dream is being organized at a gross,
<br>
imperfect level, rather than being provided in pixel-by-pixel detail by a
<br>
superintelligence.  The experiences as depicted in the movie are *not*
<br>
experiences that could be had by an uploaded cryonaut existing inside a
<br>
Friendly SI; they are experiences of a revivee still living in a
<br>
biological body and subject to gross, rather than neuron-by-neuron,
<br>
psychological surgery.  With that very important caveat, I would say that
<br>
the movie is faithful SL3 hard science fiction.
<br>
<p>To give an example of the kind of attention to detail I'm talking about -
<br>
the same attention to detail that characterized &quot;The Others&quot;, come to
<br>
think of it - the movie doesn't just suppose that cryonics patients are
<br>
put into fantasy worlds.  That would be a classic &quot;It's a plot device, we
<br>
can do anything we want&quot; dodge.  Instead, it turns out that the
<br>
protagonist specifically checked off an option on the cryonics contract
<br>
requesting a &quot;splice&quot;; that the memory of the cryonics contract, the
<br>
checking of that option, and the memory of the actual end-of-life be
<br>
eliminated, and that the apparent life continue from a moment shortly
<br>
before death.  Brian says that Alcor does *not* offer this option on the
<br>
cryo contracts... although, of course, his lack of memory is suspect. 
<br>
Right?
<br>
<p>Well, no, not really.  This is actually the main point I was thinking
<br>
about after the movie.  I find it easy to imagine a Luddite requesting a
<br>
splice post-Singularity - although I expect, and hope, that no more than a
<br>
few thousand oddballs will really go for that - but I wouldn't expect the
<br>
splicees to have the experiences depicted in the movie.  The movie is only
<br>
plausible if you assume imperfectly controlled SL3 biological dreaming,
<br>
rather than precisely controlled uploading.  The three main discordancies
<br>
with a true post-Singularity world are these:  First, the dream wouldn't
<br>
turn into a nightmare; if, somehow, things did start going wrong, it would
<br>
be spotted and corrected long before things got so far out of control. 
<br>
Second, all you need to do to wake up... if it's a Friendly AI providing
<br>
the dream... is to genuinely and fully *want* to wake up; a point the
<br>
protagonist reached fairly early on in the movie.  Third, even though it
<br>
seems like such an obvious exit from the simulation, it really shouldn't
<br>
be necessary to commit suicide as evidence of commitment.
<br>
<p>That last part probably deserves emphasis.  It is not fair, or Friendly,
<br>
to stick some poor shmuck in a simulated world and say: &quot;Well, you've
<br>
*been* provided with an exit from the simulation; if you're ever
<br>
completely sure it's a simulation, you can just jump off a roof and wake
<br>
up.&quot;  If this world is a simulation and my being here serves no useful
<br>
purpose, then I, for one, definitely and completely want to wake up right
<br>
now; if this world is real, I want to stick around and see to the
<br>
Singularity.  Jumping off a roof is only logical if you are absolutely
<br>
certain that the world is a simulation and you are absolutely certain that
<br>
&quot;death&quot; is the correct (and only) exit point.  But nobody trapped in a
<br>
simulation can ever be that sure.  The protagonist in the movie couldn't
<br>
have been sure that his experiences were the result of a simulated world,
<br>
rather than resulting from a schizophrenic breakdown in our world.
<br>
<p>In a pre-Singularity world, there is such a thing as involuntary unknowing
<br>
insanity... which means you can never be completely sure of *anything*. 
<br>
It is fair and Friendly to say &quot;If you ever decide that you want to wake
<br>
up conditional on the world being a simulation, you will wake up&quot;; it is
<br>
not fair or Friendly to require suicide as proof of sincerity.  Which
<br>
means that if you make the decision to wake up, and you *still* haven't
<br>
woken up, then you are definitely not living in a simulation being run by
<br>
a Friendly entity... which means that even if the world *is* a simulation,
<br>
suicide will probably just kill you.  (If you decide to wake up,
<br>
conditional on the world you see being a simulation that serves no useful
<br>
purpose, then you can be sure that the world is either not a Friendly
<br>
simulation, or that the world is a simulation which serves what you would
<br>
describe as a worthwhile purpose.)  Suicide as a possible way of waking up
<br>
is definitely *not* logical, as best I currently understand the rules.  I
<br>
think this is a fairly important point to establish, and even so, as with
<br>
&quot;The Matrix&quot;, I would not recommend &quot;Open Your Eyes&quot; to people who are
<br>
already mentally unstable.
<br>
<p><p><p><p><p>OKAY, SPOILERS ARE OVER.
<br>
<p><p><p><p>Sincerely,
<br>
Eliezer Yudkowsky.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://singinst.org/">http://singinst.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5973.html">Samantha Atkins: "Re: Singularity: can't happen here"</a>
<li><strong>Previous message:</strong> <a href="5971.html">Samantha Atkins: "Re: Singularity: can't happen here"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5984.html">Technotranscendence: "Re: Review of &quot;Open Your Eyes&quot;"</a>
<li><strong>Reply:</strong> <a href="5984.html">Technotranscendence: "Re: Review of &quot;Open Your Eyes&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5972">[ date ]</a>
<a href="index.html#5972">[ thread ]</a>
<a href="subject.html#5972">[ subject ]</a>
<a href="author.html#5972">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:27 MDT</em>
</em>
</small>
</body>
</html>
