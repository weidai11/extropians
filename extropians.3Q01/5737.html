<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: &quot;Machines Must Use Their Common Sense&quot; --</title>
<meta name="Author" content="J. R. Molloy (jr@shasta.com)">
<meta name="Subject" content="&quot;Machines Must Use Their Common Sense&quot; --Minsky">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>&quot;Machines Must Use Their Common Sense&quot; --Minsky</h1>
<!-- received="Tue Sep  4 08:44:03 2001" -->
<!-- isoreceived="20010904144403" -->
<!-- sent="Tue, 4 Sep 2001 07:43:10 -0700" -->
<!-- isosent="20010904144310" -->
<!-- name="J. R. Molloy" -->
<!-- email="jr@shasta.com" -->
<!-- subject="&quot;Machines Must Use Their Common Sense&quot; --Minsky" -->
<!-- id="008a01c1354f$ffae8340$6c5d2a42@jrmolloy" -->
<!-- inreplyto="01ad01c13547$05e30a00$7c0225d4@p133" -->
<strong>From:</strong> J. R. Molloy (<a href="mailto:jr@shasta.com?Subject=Re:%20&quot;Machines%20Must%20Use%20Their%20Common%20Sense&quot;%20--Minsky&In-Reply-To=&lt;008a01c1354f$ffae8340$6c5d2a42@jrmolloy&gt;"><em>jr@shasta.com</em></a>)<br>
<strong>Date:</strong> Tue Sep 04 2001 - 08:43:10 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5738.html">Eugene Leitl: "Re: Is the Internet dangerous to a political movement?"</a>
<li><strong>Previous message:</strong> <a href="5736.html">J. R. Molloy: "Re: The General Intelligence Factor"</a>
<li><strong>In reply to:</strong> <a href="5735.html">Waldemar Ingdahl: "Is the Internet dangerous to a political movement?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5744.html">J. R. Molloy: "Snubbing neo-Luddites"</a>
<li><strong>Reply:</strong> <a href="5744.html">J. R. Molloy: "Snubbing neo-Luddites"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5737">[ date ]</a>
<a href="index.html#5737">[ thread ]</a>
<a href="subject.html#5737">[ subject ]</a>
<a href="author.html#5737">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
Snarc-y AI Pioneer Minsky: Machines Must Use Their Common Sense
<br>
<a href="http://asia.dailynews.yahoo.com/headlines/technology/newsbytes/article.html?s">http://asia.dailynews.yahoo.com/headlines/technology/newsbytes/article.html?s</a>=
<br>
asia/headlines/010901/technology/newsbytes/AI_Pioneer_Minsky__Machines_Must_Us
<br>
e_Their_Common_Sense.html
<br>
CAMBRIDGE, MASSACHUSETTS, 2001 AUG 31(NB) -- By Kevin Featherly, Newsbytes.
<br>
<p>The problem is simple: people just aren't very smart. That's why we need
<br>
smart machines. Just ask Marvin Minsky.
<br>
<p>Author Steward Brand once compared Minsky to Goethe's Mephistopheles, saying
<br>
his is a &quot;fearless, amused intellect creating the new by teasing taboos.&quot; So
<br>
Minksy likes to say things like, &quot;I don't think that people are very smart,
<br>
and they need help,&quot; as he did in an interview with Newsbytes today.
<br>
<p>And don't think he doesn't believe it.
<br>
<p>Minsky, the founder of the MIT Artificial Intelligence Lab and the man often
<br>
referred to as &quot;the father of artificial intelligence,&quot; spoke with Newsbytes
<br>
about the state of AI technology on Thursday and again this afternoon.
<br>
<p>Minsky, a noted author, instructor and researcher in the AI field, has been
<br>
at work trying to raise machine intelligence to the level of humans - and
<br>
then, presumably, beyond - ever since he built the SNARC (Stochastic
<br>
Neural-Analog Reinforcement Computer), the world's first artificial neural
<br>
network, which modeled the learning process a mouse goes through as it
<br>
tracks its way through a maze. He did that, incidentally, as a graduate
<br>
student at Princeton University - in 1951.
<br>
<p>Since then, plenty has happened. In addition to AI, Minsky has made
<br>
contributions to the fields of robotics, mathematics, virtual reality, even
<br>
space exploration. He has written many books, including a science fiction
<br>
novel with Jack Williamson, &quot;The Turing Option,&quot; that explores the
<br>
possibilities of successful machine intelligence (and which places the birth
<br>
of genuine AI in the year 2023). Perhaps most famously, he worked as a
<br>
science consultant to late film director Stanley Kubrick to devise the
<br>
AI-driven HAL 2000 computer, which ended up killing an astronaut and getting
<br>
summarily unplugged in the 1969 film, &quot;2001: A Space Odyssey.&quot;
<br>
<p>But despite all his work over five decades, artificial intelligence, which
<br>
looked so promising when Minsky published the seminal white paper &quot;Steps
<br>
Towards Artificial Intelligence&quot; back in 1961, has stalled.
<br>
<p>&quot;The reason is that there are probably many years of hard research to be
<br>
done, but there are very few people working on the problem of human-level
<br>
(machine) intelligence,&quot; Minsky said. &quot;In fact, I'm trying right now to
<br>
organize a conference of about 20 people who are interested in how
<br>
common-sense reasoning works and how to organize a project to get a machine
<br>
to do it. And I can't find 20 people.&quot;
<br>
<p>The loss of momentum hasn't stopped Minsky, who today is a Toshiba Professor
<br>
of Media Arts at MIT. He remains an unflinching champion of the AI science.
<br>
In 1994, for example, he wrote an article for Scientific American magazine,
<br>
&quot;Will Robots Inherit the Earth,&quot; in which he answers his own question
<br>
enthusiastically in the affirmative.
<br>
<p>&quot;Will robots inherit the earth?&quot; he wrote. &quot;Yes, but they will be our
<br>
children. We owe our minds to the deaths and lives of all the creatures that
<br>
were ever engaged in the struggle called evolution. Our job is to see that
<br>
all this work shall not end up in meaningless waste.&quot;
<br>
<p>It's mind-bending stuff. But how long will it take to pull it off? When will
<br>
computers cease to be dumb, gussied-up adding machines and start thinking
<br>
for themselves?
<br>
<p>&quot;It's between three and 300 years,&quot; he said. &quot;Estimating how long it will
<br>
take is a combination of how large we think the problems are and how many
<br>
people will work on it.&quot;
<br>
<p>Minsky compared the situation to the problem that another AI pioneer,
<br>
Herbert A. Simon, ran into when he predicted in 1958 that it would take 10
<br>
years to create a world champion chess-playing program. Simon, who died this
<br>
year, faced a lot of criticism when, in fact, it took until 1997 for the
<br>
prediction to come true.
<br>
<p>&quot;Simon's mistake wasn't about chess,&quot; Minsky said. &quot;It was about thinking
<br>
that more people would work on it. And in fact, in that period, there were
<br>
only a couple of significant people trying to do it.&quot;
<br>
<p>Minsky laments that there are only 10 &quot;significant&quot; people in the world that
<br>
he knows who are tackling the problem of AI from the same direction he is,
<br>
which is from a basic common-sense perspective. Computers need to develop
<br>
common sense, which incidentally also means that they need to be equipped
<br>
with certain basic emotions, according to Minsky. It is probably not
<br>
necessary to make computers that can get angry, but it would be useful if
<br>
they'd get annoyed when puzzling over a problem and failing, Minsky has
<br>
said. That way they'd be likely to come back and try to solve the problem a
<br>
different way - which after all, is simply a common-sense thing to do.
<br>
<p>However, instead of taking that approach, Minsky said, most current AI
<br>
researchers are tinkering with fads from the latest peer-review journals. It
<br>
is hard to find people who want to tackle common-sense reasoning, he said,
<br>
mainly because creating common-sense responses is an enormous programming
<br>
challenge.
<br>
<p>&quot;I think when they look at it, they think that it is too hard,&quot; Minsky said
<br>
today. &quot;What happens is that people try that, and then they read something
<br>
about neural nets and say, 'Maybe if we make a baby learning machine and
<br>
just expose it to a lot, it'll get smarter. Or maybe we'll make a genetic
<br>
algorithm and try to re-evolve it, or maybe we'll use mathematical logic.'
<br>
There are about 10 fads. And the fads have eaten up everybody.&quot;
<br>
<p>Steven Spielberg hasn't helped much either, he said. While the director's
<br>
recent movie, &quot;A.I.,&quot; could have served to pique public interest (and public
<br>
funding) and driven some curious scientists into the field, instead, the
<br>
film might have done more harm than good.
<br>
<p>&quot;It was probably as negative as possible,&quot; Minsky said. &quot;It had no ideas
<br>
about intelligence in it.&quot;
<br>
<p>Minsky said he found it amusing that a Pinocchio subtext entered the movie.
<br>
&quot;I'm sure the reason is that as soon as you knew the plot, you said, 'Oh!
<br>
Pinocchio!' And Spielberg tried to head off that criticism by showing that
<br>
at least he was aware of it.&quot; Minsky said. &quot;In other words, it was just a
<br>
bad soap-opera movie. It didn't have any ideas about emotions. I think it
<br>
was a terrible film with very good photography. It didn't have anything
<br>
about what are the problems.&quot;
<br>
<p>Minsky lamented that the film wasn't made by the project's original
<br>
director, Stanley Kubrick, who died before production began. &quot;And frankly, I
<br>
was annoyed that Spielberg didn't call me. But I guess he has an aversion to
<br>
technical things.&quot;
<br>
<p>The professor is working to drum up new enthusiasm for artificial
<br>
intelligence himself, with his book, &quot;The Emotion Machine,&quot; parts of which
<br>
are online in early drafts.
<br>
<p>&quot;I hope I'll finish it in the next couple of months, but I always say that,&quot;
<br>
Minsky laughed. &quot;I'll put most of it on the Web. I want the ideas to be
<br>
available no matter how slow publishing is.&quot;
<br>
<p>The book explores the idea that emotions are simply different ways of
<br>
thinking, and that machines, to be effective, need to find various methods
<br>
of considering problems to solve them efficiently. Most computers now have
<br>
at best one or two ways to resolve problems. Minsky has some guarded hopes
<br>
that this part of AI research could move somewhat swiftly.
<br>
<p>&quot;I think it's possible that in the next 10 to 15 years we'll get machines to
<br>
do a considerable amount of common-sense reasoning, and then things might
<br>
take off,&quot; he said.
<br>
<p>The bottom line question about artificial intelligence is, why? What drives
<br>
people like Minsky to build machines that might well have intellectual
<br>
advantages over their creators? This is one of the fears that Sun
<br>
Microsystems' Bill Joy wrote about in last year's Wired magazine essay, &quot;Why
<br>
The Future Doesn't Need Us,&quot; which sent shock waves through the Silicon
<br>
Valley, prompting debate about how far such innovations as AI, robotics and
<br>
nanotechnology might go in supplanting and overpowering humanity.
<br>
<p>Minsky dismisses such fears out of hand, saying that among the research
<br>
community, they don't even register. &quot;There are deconstructionists and
<br>
strange humanists, but they don't have influence on the technical
<br>
community,&quot; he said.
<br>
<p>But Minsky doesn't mind saying exactly why he thinks humans ought to move
<br>
ahead with artificial intelligence. And it's all about our shortcomings.
<br>
Minsky thinks that human intelligence may have run its evolutionary course.
<br>
As a species, we may be at or near the end of our tethers in terms of
<br>
developing a higher order of intelligence. But with technology present to
<br>
push things ahead, Minsky suggests, why stop learning how to learn?
<br>
Intelligence is intelligence, whether it is using software or wetware (the
<br>
human brain).
<br>
<p>&quot;Humans are the smartest things around, and the question is why they aren't
<br>
smarter,&quot; Minsky said. &quot;They're sort of the only game in town. There are
<br>
elephants and porpoises, but they don't seem to go past a certain point. It
<br>
would be awful if we were the end of the road.&quot;
<br>
<p>Marvin Minsky maintains a Web site at MIT that contains many of his
<br>
writings, including early chapter drafts of his forthcoming, &quot;The Emotion
<br>
Machine.&quot; These are at <a href="http://www.ai.mit.edu/people/minsky/minsky.html">http://www.ai.mit.edu/people/minsky/minsky.html</a> .
<br>
<p>_____________________________________________________________________
<br>
«¤»¥«¤»§«¤»¥«¤»§«¤»¥«¤»«¤»¥«¤»§«¤»¥«¤»§«¤»¥«¤»§«¤»¥«¤»§«¤»¥«¤»§«¤»¥«¤
<br>
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
<br>
<p>Useless hypotheses, etc.:
<br>
&nbsp;consciousness, phlogiston, philosophy, vitalism, mind, free will, qualia,
<br>
analog computing, cultural relativism, GAC, Cyc, Eliza, cryonics, individual
<br>
uniqueness, ego
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Everything that can happen has already happened, not just once,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;but an infinite number of times, and will continue to do so forever.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Everything that can happen = more than anyone can imagine.)
<br>
<p>We won't move into a better future until we debunk religiosity, the most
<br>
regressive force now operating in society.
<br>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5738.html">Eugene Leitl: "Re: Is the Internet dangerous to a political movement?"</a>
<li><strong>Previous message:</strong> <a href="5736.html">J. R. Molloy: "Re: The General Intelligence Factor"</a>
<li><strong>In reply to:</strong> <a href="5735.html">Waldemar Ingdahl: "Is the Internet dangerous to a political movement?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5744.html">J. R. Molloy: "Snubbing neo-Luddites"</a>
<li><strong>Reply:</strong> <a href="5744.html">J. R. Molloy: "Snubbing neo-Luddites"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5737">[ date ]</a>
<a href="index.html#5737">[ thread ]</a>
<a href="subject.html#5737">[ subject ]</a>
<a href="author.html#5737">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Fri Oct 12 2001 - 14:40:25 MDT</em>
</em>
</small>
</body>
</html>
