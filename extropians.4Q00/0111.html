<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
<title>extropians: Re: Pointless Re: Eugene's nuclear threat</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Pointless Re: Eugene's nuclear threat">
</head>
<body bgcolor="#FFFFFF" text="#000000">
<h1>Re: Pointless Re: Eugene's nuclear threat</h1>
<!-- received="Mon Oct  2 14:07:11 2000" -->
<!-- isoreceived="20001002200711" -->
<!-- sent="Mon, 02 Oct 2000 16:08:18 -0400" -->
<!-- isosent="20001002200818" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Pointless Re: Eugene's nuclear threat" -->
<!-- id="39D8EB32.CCF01D47@posthuman.com" -->
<!-- inreplyto="14808.48343.775104.575375@lrz.uni-muenchen.de" -->
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D8EB32.CCF01D47@posthuman.com&gt;"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Mon Oct 02 2000 - 14:08:18 MDT
<p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0112.html">Dan Fabulich: "Intelligence increase was: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0110.html">J. R. Molloy: "Peering into the ozone hole"</a>
<li><strong>In reply to:</strong> <a href="0101.html">Eugene Leitl: "Pointless Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0280.html">Eugene Leitl: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#111">[ date ]</a>
<a href="index.html#111">[ thread ]</a>
<a href="subject.html#111">[ subject ]</a>
<a href="author.html#111">[ author ]</a>
</ul>
<hr noshade><p>
<!-- body="start" -->
<p>
You must be suffering some serious cognitive dissonance about now, since
<br>
your chosen area of study is exactly the thing that may open Pandora's box
<br>
so to speak. And it isn't just us- you've got your favorite de Garis who
<br>
is just waiting for faster processing, plus the following bit from the SL4
<br>
list last night will also probably give you severe indigestion. You know
<br>
actually SIAI has got to be the least of your worries since we have no
<br>
plans at this point to make use of evolutionary programming techniques...
<br>
<p>-------- Original Message --------
<br>
Subject: RE: Ben what are your views and concerns
<br>
Date: Sun, 1 Oct 2000 23:25:06 -0400
<br>
From: &quot;Ben Goertzel&quot; &lt;<a href="mailto:ben@intelligenesis.net?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D8EB32.CCF01D47@posthuman.com&gt;">ben@intelligenesis.net</a>&gt;
<br>
Reply-To: <a href="mailto:sl4@sysopmind.com?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D8EB32.CCF01D47@posthuman.com&gt;">sl4@sysopmind.com</a>
<br>
To: &lt;<a href="mailto:sl4@sysopmind.com?Subject=Re:%20Pointless%20Re:%20Eugene's%20nuclear%20threat&In-Reply-To=&lt;39D8EB32.CCF01D47@posthuman.com&gt;">sl4@sysopmind.com</a>&gt;
<br>
<p><p>hi,
<br>
<p><em>&gt; Ben do you have any concerns about runaway AI, or even if you
</em><br>
<em>&gt; believe human-
</em><br>
<em>&gt; equiv AIs will be controllable do you worry about some of the
</em><br>
<em>&gt; evil or simply
</em><br>
<em>&gt; shortsighted things they may be used for (especially if they get
</em><br>
<em>&gt; open sourced)?
</em><br>
<p>I don't have ~big~ concerns about AI that becomes evil
<br>
due to its own purely AI motivations
<br>
<p>I do worry, though, about evil humans using AI in evil ways
<br>
<p>See, Internet AI systems aren't going to have an inbuilt urge for
<br>
aggression -- they're not growing up
<br>
in a predator-prey ecosystem... they'll mainly grow up to help and serve
<br>
people in various ways; their
<br>
&quot;fitness&quot; won't have to do with killing other creatures or becoming &quot;leader
<br>
of the pack,&quot; but rather with
<br>
being as useful as possible to their human masters...
<br>
<p>What kinds of weird AI psychology will emerge once AI systems move on beyond
<br>
being primarily servants
<br>
to humans... I don't know, but have speculated
<br>
<p>Here is a moderately brief excerpt from my forthcoming book &quot;Creating
<br>
Internet Intelligence&quot; (Plenum press), which verges
<br>
on this topic:
<br>
<p>-- ben
<br>
<p><p>****
<br>
With something as new and different as this [Internet AI], it would be easy
<br>
to slip up and create a disaster.  Or would it?   Maybe there are inexorable
<br>
forces of evolution at work here, and the conscious acts that we take are
<br>
just tiny little nudges one way or the other.  Maybe if a disaster is
<br>
inevitable, there's no act that any of us could take to stop it anyway?
<br>
Anything's possible, of course, and in the presence of so many unknowns,
<br>
assigning probabilities to various outcomes is going to be more intuitive
<br>
than rational.  My intuition is that what's going to happen will be good -
<br>
intelligence, creativity and passion will be served; instinctive, habitual
<br>
routines will be loosened; the process of forming and destroying boundaries
<br>
between people, groups and ideas will transform into something we can't yet
<br>
understand.  But this is just the intuition of my little human brain,
<br>
supercharged by whatever &quot;collective unconscious&quot; forces it's managed to tap
<br>
into.  How to assess how much this is worth?
<br>
<p>Much of my intuition about the long-term future of the Net comes from my
<br>
work on Webmind.  Webminds, as individual minds, are going to be useful for
<br>
various practical applications as described in the previous chapter; but
<br>
they'll also be autonomous, self-directed systems, concerned with achieving
<br>
their own goals and their own happiness.  What happens when the Internet is
<br>
dominated by a community of AI agents, serving commercial, collective and
<br>
individual goals?  What will be the nature of this Webmind society, and its
<br>
implications for us?
<br>
<p>Of course, Webmind society is not going to be the Internet as a whole.  But
<br>
there's reason to believe that the core of the first phase of the
<br>
intelligent Internet will indeed be centered on a community of powerful AI
<br>
agents.  And if this is true, that's all the more reason to understand how
<br>
these agent societies are going to operate.  For example, what's the chance
<br>
that Webminds and other AI agents are going to sit around all day exchanging
<br>
encrypted messages about how to accelerate the obsolescence of the human
<br>
race?
<br>
<p>I don't know the answers to these questions, but I've thought about them a
<br>
good bit, and discussed them with others.  In this chapter I'll give some
<br>
ideas about Webmind societies, and their implications for the future of the
<br>
Net in general.  In concrete terms, these ideas concern the Intelligent
<br>
Internet phase, more so than the Global Brain phase - they have to do with
<br>
computer programs on the Net, not with human brains jacked into the Net,
<br>
bio-digital intelligence, or the behavior of AI systems filled with the
<br>
contents of uploaded human minds.  But, thinking more laterally, it seems
<br>
likely that the nature of the society of AI agents in the Intelligent
<br>
Internet phase is going to be critical in setting the stage for the nature
<br>
of the true Global Brain to follows.  If this is the case, then Webmind
<br>
societies are truly a highly important issue.
<br>
<p>The Webmind Inc. &quot;tech list&quot; e-mail discussion group has sustained a number
<br>
of long threads on the topic of Webmind morality, and social interaction
<br>
among groups of Webminds.  These discussions sometimes seem frivolous, mixed
<br>
in as they are with reports of bugs in Webmind's basic thinking processes,
<br>
basic questions about Java programming and Webmind structure from new
<br>
employees, and debates over new features in Webmind's reasoning, language,
<br>
or data analysis modules . but, although they sometimes are frivolous, they
<br>
are also important.  We all proceed fairly blindly into future, but if we
<br>
squint our eyes hard enough, we can see a little bit, and after a lot of
<br>
thinking about where we want to go, we can have at least a little input into
<br>
our direction of movement.  In many areas these internal company discussions
<br>
have gone far deeper than the discussions on the Global Brain mailing list,
<br>
as excerpted above.
<br>
<p>One consequence of our discussions on Webmind morality has been the
<br>
realization that Teilhard really was wrong - the global brain will not be
<br>
perfect!   In fact, the same flaws that plague human society will plague the
<br>
Intelligent Internet, though hopefully to a lesser degree, and definitely
<br>
with a different flavor.  Furthermore, as a consequence of this, the
<br>
convergence of the Net with the Jungian vision of the collective unconscious
<br>
will be greater than it might seem at first glance.  Many of the archetypes
<br>
of the human unconscious emerge from socialization, from the dynamics of
<br>
society.  And there are certain aspects of social dynamics that seem to be
<br>
universal, that are bound to emerge in the global brain once it reaches a
<br>
certain level of complexity, just as they have emerged among humans.
<br>
<p>We've seen how it's possible to embody a Webmind with compassion - you
<br>
program it so that its happiness will increase when it senses that the other
<br>
actors it interacts with are happy.  One then has a collection of Webminds
<br>
that want to please each other.  This enhances the intelligence of the
<br>
overall community of Webminds, because the Webminds have an intrinsic
<br>
motivation to supply each other with the best answers to their questions,
<br>
and to provide each other with resources when needed.  If this were Webminds
<br>
' only motivation, one would soon have a community of morons, babbling
<br>
digital nonsense to each other in a chorus of mutually supportive, ignorant
<br>
bliss.  But overlaid on a system in which Webminds achieve happiness by
<br>
creating patterns and satisfying users, and pay each other for intelligent
<br>
answers to their questions, compassion enhances emergent intelligence.  This
<br>
hasn't been proven in practice yet, since we have not yet built a large
<br>
network of Webminds.  But we've set up simulations that have borne out this
<br>
intuition.
<br>
<p>So far, so good.  But what happens when someone introduces a
<br>
non-compassionate Webmind (or another non-compassionate intelligent actor)
<br>
into the mix?  A whole system of selfish Webminds works worse than a whole
<br>
system of compassionate Webminds.  But is global compassion a stable
<br>
situation?  One selfish Webmind, in a compassionate community, will have an
<br>
intrinsic advantage - it will in effect be able to make itself king.  More
<br>
and more selfish Webminds will then get introduced into the system, as
<br>
others see the value of selfishness for achieving their goals.  The
<br>
compassionate society will dissolve.
<br>
What's the solution?  One answer is benevolent fascism.  Erect a global
<br>
authority, which makes sure that only compassionate Webminds get released
<br>
into the Net.  But this will never work.  The Net is too disorganized and
<br>
self-organized; no one owns it.
<br>
<p>The only other answer that I see is, painfully enough, social ostracism.
<br>
Compassionate Webminds need to take a &quot;tough love&quot; approach to selfish
<br>
Webminds, and refuse to deal with them, even if it would be to their
<br>
short-term economic advantage to do so.  It then becomes a bad strategy for
<br>
a single Webmind to be selfish.   This seems simple enough.  But the problem
<br>
is, how do you recognize selfishness, from the outside?  It's not so easy.
<br>
This is just another tough pattern recognition problem.  Seeing examples of
<br>
selfishness, and knowing some properties of selfishness, Webmind can learn
<br>
to recognize selfishness by certain signs.  But then, Webminds will get a
<br>
hang of the &quot;selfishness recognition systems&quot; of other Webminds, and learn
<br>
how to fool each other.  Just as humans trick each other by false facial
<br>
expressions and tones of voice.   And furthermore, there will be Webminds
<br>
that are perfectly compassionate, but that unintentionally give the signs of
<br>
being selfish - &quot;false negatives&quot; for the selfishness recognition systems of
<br>
their fellow Webminds.
<br>
<p>You have to act right to be accepted.  If you don't act right, nobody wants
<br>
to talk to you.  Some of the ways of acting &quot;wrong&quot; may actually better than
<br>
the accepted ways of doing things, but no one seems to recognize this.  You
<br>
either have to go along with the majority, accept your isolation, or band
<br>
together with similar freaks who go against the prevailing standard of what
<br>
is the correct way to be.  This may sound familiar to many readers - it is
<br>
definitely familiar to me, from my teenage years, particularly the five
<br>
miserable years I spent in middle school and high school, before leaving for
<br>
college.  Unfortunately, it seems that a certain amount of this stuff is
<br>
going to be there in Webmind communities as well.  Not all of the nastiness
<br>
of human society can be avoided, some of it is an inevitable consequence of
<br>
the information-processing restrictions imposed by the finitude of mind.  We
<br>
can't tell what's really good or not, so we have to estimate, and our
<br>
estimation errors may be painful for their victims.
<br>
<p>And what happens when a band of freaks, going against the prevailing
<br>
standards of right, gets large enough?  It becomes an alternative community.
<br>
You then have two groups, each one of which judges goodness according to its
<br>
own criteria, its own estimates.  Each one may judge the other one as bad.
<br>
And - maybe - try and wipe the other one out, in the name of goodness?
<br>
Will things go this far in Webmind society?  Will warfare erupt among
<br>
Webminds, based on differing groups that use different pattern recognition
<br>
algorithms to estimate goodness?  Actually I doubt it.  The saving grace of
<br>
digital intelligence, I believe, will be its adaptability.  Webminds can
<br>
change much more rapidly than humans.  Potentially, they can even revise
<br>
their brains.  Right now this is well beyond any existing software, but in a
<br>
decade or so, we may have Webminds that can rewrite their own Java code to
<br>
improve functionality.
<br>
<p>I don't think there is much relation between the goodness of a society and
<br>
the intelligence of the actors who make it up.  Yes, more intelligent actors
<br>
can figure out what features indicate goodness better.  On the other hand,
<br>
they can also figure out how to fool each other better.  The two factors
<br>
probably balance out.  On the other hand, I do think that adaptability
<br>
encourages goodness.  A fair amount of the stupidity of human society can be
<br>
traced to our slow adaptation, in particular to the inability of our brains
<br>
to respond to cultural changes.
<br>
<p>We humans are to a great extent locked in by our evolutionary history.
<br>
There are hundreds of examples of this - one is the way that women's sexual
<br>
infidelity is treated much more seriously than men's, in all human cultures.
<br>
Many women find this unfair, and I would too in their place, but the reason
<br>
is obvious, if one takes a sociobiological, DNA-centric view.  If a woman
<br>
has a baby by a different man than her husband, then the husband, insofar as
<br>
he is supporting and protecting the child, is wasting his time propagating
<br>
someone else's DNA.  His DNA is angry: it wants to propagate itself.  On the
<br>
other hand, if a man impregnates a different woman than his wife, this doesn
<br>
't matter much to the wife's DNA.   All her DNA wants is for the husband to
<br>
keep supporting her children, which carry it into the future.  So the extra
<br>
stigma attached to female infidelity makes sense from an evolutionary
<br>
perspective.  But from a modern human perspective, it is almost completely
<br>
obsolete.   Now, women can use birth control, hence they can sleep around
<br>
without much risk of pregnancy.   Also, most women are no longer producing
<br>
children on a continual basis, so that most acts of infidelity do not
<br>
produce any question of paternal identity.  Finally, we have DNA testing, so
<br>
that, in principle, every new father can test his child's DNA to see if he's
<br>
the real father or not, thus eliminating the risk of his DNA wasting much of
<br>
its effort propagating a competing DNA pattern.  Have these developments
<br>
decreased the stigma attached to female infidelity?  Yes, a bit.  Cheating
<br>
women are no longer routinely killed.  We are not completely pawns of our
<br>
evolutionary heritage.  But, they have not decreased it as much as they
<br>
should have, and they probably never will.  Our mechanisms for judging
<br>
others are not very adaptive.
<br>
<p>To take another example, Freud, in &quot;Civilization and Its Discontents&quot;
<br>
(1984),  argued that neurosis is a necessary consequence of civilization.
<br>
His reason was that civilization requires us to check our primitive impulses
<br>
toward violence, to restrict our behavior in biologically unnatural ways.
<br>
In the terms I am using here, what was good in the contest of tribal society
<br>
is no longer good in modern society, and this causes problems.  Webminds
<br>
will not have much of this kind of problem: faced with the situation Freud
<br>
describes, they would just rewire themselves to be less violent.
<br>
Webmind society will thus be very different from ours.  Social codes and
<br>
standards will change continually and rapidly.  It is hard to imagine what
<br>
it would be like to live in such a way - but it's not impossible.  Because,
<br>
after all, social codes and standards are changing more rapidly every
<br>
decade.  Society has moved into fast-forward mode.  Aboriginals dressed and
<br>
acted the same way for sixty thousand years; now styles change every six
<br>
months.  The dynamism of internet intelligence and the dynamism of
<br>
contemporary culture will intersect to give the global societal mind a
<br>
colorful, vibrant, wild character that
<br>
I could express in music or pictures much more easily than in words.
<br>
<p>Many features derived from human sexuality will be missing from Webmind
<br>
society, since the types of reproduction available to Webminds will be much
<br>
more diverse: a Webmind can clone itself, or can &quot;cross over&quot; with any
<br>
number of other Webminds, yielding Webminds with 2, 3, or 100,000 parents.
<br>
Furthermore a Webmind can be progressively altered by itself or its owner,
<br>
yielding a continuous evolution of personality that is not accessible to
<br>
humans at all, due to our inability to modify our own brain structure except
<br>
crudely through drugs.  But even with this new diversity, much of the
<br>
archetypal structure of human relationships will be there.  We know, from
<br>
our research with genetic algorithms, that sexual reproduction is much more
<br>
efficient than asexual reproduction by fission or continuous development.
<br>
So Webminds will reproduce sexually even though they have other options open
<br>
to them.  And genetic algorithm experiments show that multi-parent
<br>
reproduction is not significantly more effective than two-parent
<br>
reproduction.  So many Webminds will have two parents, though there will be
<br>
no difference between mom and dad.
<br>
<p>Webminds will be careful about whom they reproduce with.  If a Webmind has
<br>
access to certain resources, in which it wants to place one of its children,
<br>
it will want to make this child as good a child as possible.  Furthermore,
<br>
once it has observed that it can produce a good child with another Webmind,
<br>
it may want to maintain this relationship over time.
<br>
&quot;Childhood&quot; among Webminds will not necessarily mean the same thing as it
<br>
does among humans.  It is possible for two Webminds to mate and birth a
<br>
fully-formed Webmind, ready for action.  On the other hand, it may be very
<br>
useful for a Webmind to create a &quot;baby Webmind&quot;, with a partially empty
<br>
brain.  In this way it may arrive at something much smarter than itself, or
<br>
at least something with new and different ideas.  A baby Webmind, however,
<br>
will require a teacher.  The notion of parental responsibility arises.
<br>
Webminds that take good care of their babies will be more likely to produce
<br>
successful babies.  Thus, by evolutionary pressure, Webminds will come to
<br>
have an &quot;instinct&quot; that taking care of baby Webminds is good.  The urge to
<br>
take care of baby Webminds will be automatically passed along from parent to
<br>
child..
<br>
<p>And so it goes.  The community of Webminds will not be exactly like human
<br>
society - far from it.  But it will not be entirely different either.  The
<br>
Jungian archetypes of union, child, family, will all be there, overlaid with
<br>
other archetypes that we can barely even envision, all improvising on the
<br>
theme of the basic numerical archetypes, the combinations of 0's and 1's
<br>
that make up the mind and the world.  The human collective unconscious will
<br>
be made concrete via the action of intelligent actors on human text and on
<br>
numerical data representing human activities.  But it will be made non-human
<br>
via the intrinsic peculiarities of these intelligent actors and their
<br>
interactions.  Their own unconscious patterns will filter down into human
<br>
society, so that we are affected in subtle ways by the feeling a digital
<br>
actor gets when it has 1000 parents, as opposed to 1 or 2.  Much of each
<br>
human being's brain will be filled with patterns and ideas of digital
<br>
origin, just as much of the intelligent Internet will be filled with
<br>
patterns and ideas of human origin.  All this is bound to occur as a
<br>
consequence of our incessant daily interaction with the Net, and the Net's
<br>
increasing self-organizing intelligence.
<br>
<p>...
<br>
<p>*****
<br>
<p>Eugene Leitl wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Brian Atkins writes:
</em><br>
<em>&gt;  &gt; Eugene this is going nowhere for one reason: look around at the real world
</em><br>
<em>&gt;  &gt; (as you love to point out)- there are no Turing Police out there, and I
</em><br>
<em>&gt;  &gt; don't see any developing. I don't know why we are wasting our time debating
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Perhaps there should be one.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; this, since your wishes for temporary relinquishment will not come to pass
</em><br>
<em>&gt;  &gt; (at least in the AI area) IMO. Or are you planning to start your own org
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I agree this was a bit too verbose, but at least for me the debate was
</em><br>
<em>&gt; fruitful. The logics of it all drove me to adopt a position I formerly
</em><br>
<em>&gt; wouldn't dream to hold. Strange, strange world.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  &gt; politicking for these measures and controls?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; No, I'm more interested in nanotechnology, specifically molecular
</em><br>
<em>&gt; circuitry. I'm no good at politics, and I don't see the threat to
</em><br>
<em>&gt; become relevant before two to three decades have passed. If my mental
</em><br>
<em>&gt; facilities are then still sufficient, we will see then.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Meanwhile, I would ask of you and Eliezer to reevaluate your project,
</em><br>
<em>&gt; specifically reassessing that what you're trying to build is indeed
</em><br>
<em>&gt; that what you will wind up with, especially if you decide to use
</em><br>
<em>&gt; evolutionary algorithms as part of the seed technology.
</em><br>
<p><pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.singinst.org/">http://www.singinst.org/</a>
</pre>
<p><!-- body="end" -->
<hr noshade>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0112.html">Dan Fabulich: "Intelligence increase was: Eugene's nuclear threat"</a>
<li><strong>Previous message:</strong> <a href="0110.html">J. R. Molloy: "Peering into the ozone hole"</a>
<li><strong>In reply to:</strong> <a href="0101.html">Eugene Leitl: "Pointless Re: Eugene's nuclear threat"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0123.html">J. R. Molloy: "Re: Pointless Re: Eugene's nuclear threat"</a>
<li><strong>Reply:</strong> <a href="0280.html">Eugene Leitl: "Re: Pointless Re: Eugene's nuclear threat"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#111">[ date ]</a>
<a href="index.html#111">[ thread ]</a>
<a href="subject.html#111">[ subject ]</a>
<a href="author.html#111">[ author ]</a>
</ul>
<!-- trailer="footer" -->
<hr noshade>
<p>
<small>
<em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2b30</a> 
: <em>Mon May 28 2001 - 09:50:14 MDT</em>
</em>
</small>
</body>
</html>
