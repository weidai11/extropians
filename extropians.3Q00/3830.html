<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
                      "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>
<TITLE>extropians: The Last Computer</TITLE>
<META NAME="Author" CONTENT="Spudboy100@aol.com (Spudboy100@aol.com)">
<META NAME="Subject" CONTENT="The Last Computer">
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<H1>The Last Computer</H1>
<!-- received="Wed Aug 30 16:57:03 2000" -->
<!-- isoreceived="20000830225703" -->
<!-- sent="Wed, 30 Aug 2000 18:57:37 EDT" -->
<!-- isosent="20000830225737" -->
<!-- name="Spudboy100@aol.com" -->
<!-- email="Spudboy100@aol.com" -->
<!-- subject="The Last Computer" -->
<!-- id="14.879876b.26deeb61@aol.com" -->
<STRONG>From:</STRONG> <A HREF="mailto:Spudboy100@aol.com?Subject=Re:%20The%20Last%20Computer&In-Reply-To=&lt;14.879876b.26deeb61@aol.com&gt;"><EM>Spudboy100@aol.com</EM></A><BR>
<STRONG>Date:</STRONG> Wed Aug 30 2000 - 16:57:37 MDT
<P>
<!-- next="start" -->
<UL>
<LI><STRONG>Next message:</STRONG> <A HREF="3831.html">CYMM: "Mysticism (WAS) E.S.P. in the Turing Test"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3829.html">QueeneMUSE@aol.com: "Re: E.S.P. in the Turing Test"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3866.html">Adrian Tymes: "Re: The Last Computer"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3866.html">Adrian Tymes: "Re: The Last Computer"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3830">[ date ]</A>
<A HREF="index.html#3830">[ thread ]</A>
<A HREF="subject.html#3830">[ subject ]</A>
<A HREF="author.html#3830">[ author ]</A>
</UL>
<HR NOSHADE><P>
<!-- body="start" -->
<P>
www.Newscientist.com
<BR>
<P>Here is an article that focuses on theorist, Seth Lloyd. A goodie article for 
<BR>
Omega Pointers, and Singularity Mavens.
<BR>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The Last Computer
<BR>
One day you'll be sitting in front of a searing-hot nuclear fireball instead 
<BR>
of that inert grey box, says Marcus Chown 
<BR>
<P><P>SETH LLOYD has seen the future of computing, and it's bright. Blindingly 
<BR>
bright. For, according to Lloyd, the ultimate computer will be nothing like 
<BR>
an IBM ThinkPad and everything like a &quot;billion-degree piece of the big bang&quot;. 
<BR>
<P>Before you dismiss the idea, just consider the awesome power you would have 
<BR>
at your disposal. According to Lloyd's calculations, the ultimate laptop 
<BR>
could solve in less than a nano-second a calculation that would take any 
<BR>
state-of-the-art computer the age of the Universe to complete. 
<BR>
<P>Admittedly, it might be a bit inconvenient putting a nuclear fireball on your 
<BR>
desk. But that is only the most ordinary, conventional kind of ultimate 
<BR>
computer--the alternative could be something stranger still. 
<BR>
<P>The train of thought that led to these bizarre physical extremes started from 
<BR>
a simple observation. Gordon Moore, a co-founder of the computer chip maker 
<BR>
Intel, noticed in 1965 that the number of transistors per square inch on 
<BR>
chips had doubled every 18 months or so since the integrated circuit was 
<BR>
invented. This trend has continued. Experts are divided over how much longer 
<BR>
the law will hold, but Lloyd for one is fed up with people constantly writing 
<BR>
it off. &quot;People have been claiming the law is about to break down every 
<BR>
decade since it was formulated,&quot; says Lloyd, a physicist based at MIT. &quot;But 
<BR>
they've all been wrong. I thought, let's see where Moore's law has to stop 
<BR>
and can go no further. Let's find the limits that no amount of human 
<BR>
ingenuity will ever be able to get around.&quot; 
<BR>
<P>To begin with, he wasn't too concerned with the details of how the ultimate 
<BR>
computer might work--those can be sorted out by the engineers of the future. 
<BR>
Instead, he stuck to considering basic physical quantities such as energy, 
<BR>
volume and temperature (Nature, vol 406, p 1047). 
<BR>
<P>The speed of a computer, Lloyd realised, is limited by the total energy 
<BR>
available to it. The argument for this is rather subtle. A computer performs 
<BR>
a logical operation by flipping a &quot;0&quot; to a &quot;1&quot; or vice versa. But there is a 
<BR>
limit to how fast this can be done because of the need to change a physical 
<BR>
state representing a &quot;0&quot; to a state representing a &quot;1&quot;. In the quantum world 
<BR>
any object, including a computer, is simply a packet of waves of various 
<BR>
frequencies all superimposed. Frequency is linked to energy by Planck's 
<BR>
constant, so if the wave packet has a wide range of energies, it is made up 
<BR>
of a large range of different frequencies. As these waves interfere with one 
<BR>
another, the overall amplitude can change very fast. On the other hand, a 
<BR>
small energy spread means a narrow range of frequencies, and much slower 
<BR>
changes in state. 
<BR>
<P>Because a computer can't contain negative energies, the spread in energy of a 
<BR>
bit cannot be greater than its total energy. In 1998, Norman Margolus and Lev 
<BR>
Levitin of MIT calculated that the minimum time for a bit to flip is Planck's 
<BR>
constant divided by four times the energy. 
<BR>
<P>Lloyd has built on Margolus's work by considering a hypothetical 1-kilogram 
<BR>
laptop. Then the maximum energy available is a quantity famously given by the 
<BR>
formula E = mc2. &quot;If this mass-energy were turned into a form such as radiant 
<BR>
energy, you'd have 1017 joules in photons,&quot; says Lloyd. &quot;And, if you put all 
<BR>
this energy in a single bit, it could flip in 10-51 seconds.&quot; But quantum 
<BR>
physicists believe the shortest possible time for any event to occur is the 
<BR>
&quot;Planck time&quot; of 10-43 seconds. &quot;Something is screwy,&quot; says Lloyd. 
<BR>
<P>In practice, computers do not have a single bit of memory but lots of bits. 
<BR>
If the energy of the 1-kilogram laptop were spread among more than a billion 
<BR>
bits, each would flip more slowly than the Planck time. &quot;Although each bit 
<BR>
would flip more slowly, there would be more of them,&quot; says Lloyd, &quot;so the 
<BR>
total number of bit-flips per second would be the same.&quot; 
<BR>
<P>So the ultimate laptop, one that has converted all its mass-energy to 
<BR>
radiation, would be able to carry out a mind-boggling 1051 operations per 
<BR>
second. Compare this with today's standard laptop, which has a clock speed of 
<BR>
about 500 megahertz and carries out up to 1000 parallel operations each 
<BR>
cycle--a total of about 1012 operations per second. The ultimate laptop would 
<BR>
be 1039 times faster. If even that is too slow for you, you can add more 
<BR>
mass--a 1000-kilogram computer would be a thousand times faster, for example. 
<BR>
What's more, says Lloyd, the ultimate laptop would be a quantum computer, 
<BR>
able to exploit an unimaginable number of superimposed states, solving 
<BR>
certain kinds of problem (such as factorising large numbers) far faster than 
<BR>
a classical computer. 
<BR>
<P>&nbsp;&nbsp;
<BR>
Photography: Ian Jackson 
<BR>
&nbsp;
<BR>
Why then are today's laptops so damned slow? The simple answer, says Lloyd, 
<BR>
is they use only the electromagnetic energy of electrons moving through 
<BR>
transistors, and this energy is dwarfed by the energy locked away in the mass 
<BR>
of the computer, which provides nothing more than the scaffolding to keep a 
<BR>
computer stable. The ultimate laptop would have all of its available energy 
<BR>
in processing interactions and none of its energy in dumb mass. 
<BR>
<P>With that sort of computing power, astrophysicists could simulate the whole 
<BR>
Universe on the scale of stars, and physicists could simulate a large lump of 
<BR>
matter on the scale of individual atoms--and just think of the possibilities 
<BR>
for realistic computer games. 
<BR>
<P>So much for speed. What limits memory? The short answer is entropy. This is 
<BR>
the degree of disorder, or randomness, in a system. Entropy is intimately 
<BR>
connected to information, because information needs disorder: a smooth, 
<BR>
ordered system has almost no information content. 
<BR>
<P>State limits 
<BR>
<P>Entropy is linked to the number of distinguishable states a system can have 
<BR>
by the equation inscribed on Boltzmann's headstone S = k ln W. Entropy (S) is 
<BR>
the natural logarithm of the number of states (W) multiplied by Boltzmann's 
<BR>
constant (k). Equally, to store a lot of information, you need a lot of 
<BR>
distinguishable states. To register one bit of information, you need two 
<BR>
states, one representing &quot;on&quot;, the other &quot;off&quot;. Similarly, 2 bits require 4 
<BR>
states, 3 bits 8 states, and so on. In short, both the entropy of a system 
<BR>
and its information content are proportional to the logarithm of the number 
<BR>
of states. &quot;The answer to the question--what is the maximum memory of a 
<BR>
computer?--can actually be found on Boltzmann's headstone,&quot; says Lloyd. 
<BR>
<P>So how much entropy does one of Lloyd's computers have? It depends on the 
<BR>
volume of the computer, as well as its energy. Broadly speaking, the more 
<BR>
volume, the more possible positions of particles in the computer, so the more 
<BR>
available states. For his ultimate laptop, Lloyd picked a convenient 1-litre 
<BR>
size. 
<BR>
<P>The exact calculation also depends on how many different kinds of particle 
<BR>
are knocking around inside the computer. &quot;If all the mass-energy of the 
<BR>
computer is used, we're talking about converting it into light,&quot; he says. &quot;So 
<BR>
what we need to calculate is the number of distinguishable states available 
<BR>
to a box of light--this is a calculation carried out by Max Planck for a 
<BR>
so-called black body a century ago.&quot; 
<BR>
<P>It turns out that a litre of light could store about 1031 bits, 1020 times as 
<BR>
much as a modern 10-gigabyte hard drive. Today's laptops store so little 
<BR>
information, says Lloyd, because they store it in an extremely redundant 
<BR>
fashion. A single bit on your hard drive is stored by a &quot;magnetic domain&quot; 
<BR>
which may contain millions of atoms. 
<BR>
<P>All in all, the ultimate laptop would look pretty weird. With all that 
<BR>
radiant energy squeezed into such a small space, it would be fantastically 
<BR>
hot, around a billion degrees. The &quot;light&quot; would actually be high-energy 
<BR>
gamma-ray photons. &quot;Controlling all that energy--that's the challenge,&quot; says 
<BR>
Lloyd. 
<BR>
<P>Assuming we could contain this sizzling soup, it might work something like 
<BR>
this. Information would be stored in the positions and trajectories of 
<BR>
gamma-ray photons, and processed by collisions between these photons and the 
<BR>
few electrons and positrons also floating around. 
<BR>
<P>&nbsp;
<BR>
Photography: Ian Jackson 
<BR>
&nbsp;
<BR>
<P>Readout would be easy. &quot;You simply open up a hole in the side of the box,&quot; 
<BR>
says Lloyd. &quot;The photons come out at the speed of light, and you record the 
<BR>
sequence of clicks on a gamma-ray detector.&quot; Input would require some sort of 
<BR>
controlled gamma-ray generator. Of course, all these accessories would take 
<BR>
useful mass-energy away from the central processor, but Lloyd assumes it will 
<BR>
eventually be possible to make them very small and light. 
<BR>
<P>But whatever cunning technology is used for input and output, this version of 
<BR>
the ultimate laptop has a serious design flaw. Information can't be moved in 
<BR>
and out of the computer faster than light, so assuming that the 1-litre 
<BR>
laptop is a cube with 10-centimetre sides, all of its 1031 or so bits of 
<BR>
memory could be dumped in the time taken for light to travel 10 
<BR>
centimetres--3 10-10 seconds. 
<BR>
<P>That gives a data transfer rate of nearly 1041 bits per second. But 
<BR>
potentially, the computer can perform a total of 1051 operations in that 
<BR>
second. The same goes for any substantial chunk of the computer--it can do 
<BR>
far more calculations than it can communicate to other parts of the computer. 
<BR>
So each subsection would have to work independently. &quot;This is a highly 
<BR>
parallel machine,&quot; says Lloyd. 
<BR>
<P>And this information bottleneck has serious implications for error 
<BR>
correction. Error-correcting codes check computer calculations to find out 
<BR>
whether something's gone wrong. But in the ultimate laptop, any erroneous 
<BR>
bits would have to be physically taken out of the computer, radiated away and 
<BR>
replaced by new bits. This version of the ultimate laptop can discard no more 
<BR>
than 1041 errors while it makes 1051 calculations, so it can tolerate only 
<BR>
one error for every ten billion operations. If that accuracy can't be 
<BR>
achieved, the 1-litre laptop would have to operate at below the ultimate 
<BR>
speed limit. 
<BR>
<P>So is there any way to increase the input/output rate? &quot;Yes,&quot; says Lloyd. 
<BR>
&quot;Make the laptop smaller.&quot; If the size is reduced it takes less time for 
<BR>
information to move around, and there is less memory to be moved, so the 
<BR>
computer becomes more serial. In general, serial calculations are more 
<BR>
versatile, because highly parallel computers only work if the input and 
<BR>
output are brief, containing far less information than the total amount 
<BR>
processed in the course of the calculation. 
<BR>
<P>The 1-litre ultimate laptop is already at about a billion degrees. But as it 
<BR>
is compressed the temperature rises and other, more exotic, particles can be 
<BR>
conjured into existence. &quot;Computers of the future may be high-power 
<BR>
relativistic devices similar to particle accelerators,&quot; says Walter Simmons 
<BR>
of the University of Hawaii at Manoa. Simmons and his colleagues Sandip 
<BR>
Pakvasa and Xerxes Tata have explored the far future of so-called 
<BR>
relativistic computing, involving interactions between known physical 
<BR>
particles. But they have not pursued that future to the giddy limits 
<BR>
envisaged by Lloyd. &quot;As the temperature rises and ever-more exotic particles 
<BR>
can be created, our knowledge of the physics gets shakier and shakier,&quot; he 
<BR>
says. Fortunately, though, there comes a time when the physics becomes simple 
<BR>
again. 
<BR>
<P>If you keep squashing the computer, eventually it will turn into a black 
<BR>
hole. The whole mass of the 1-kilogram laptop would then be squeezed into a 
<BR>
volume little more than 10-27 metres across. How can this still be a 
<BR>
computer? 
<BR>
<P>Stephen Hawking of the University of Cambridge theorised in 1970 that a black 
<BR>
hole should evaporate, emitting light and elementary particles from its 
<BR>
horizon, the surface that marks the point of no return for objects falling 
<BR>
in. Thermodynamics says that any radiating body has entropy, and in 1972 
<BR>
Jacob Bekenstein calculated how much a black hole must have. If we equate 
<BR>
entropy with information, this means that a 1-kilogram black hole can store 
<BR>
around 1016 bits. 
<BR>
<P>According to conventional physics, as espoused by Hawking among others, any 
<BR>
information that goes into a black hole is lost to the rest of the Universe. 
<BR>
That would rule out using a black hole as a computer. But string theorists 
<BR>
think otherwise. &quot;Hawking raised an important question,&quot; says Gordon Kane of 
<BR>
the University of Michigan, Ann Arbor. &quot;But there is evidence that string 
<BR>
theory will show that something happens to preserve the information.&quot; Lloyd 
<BR>
believes that information about how a black hole was formed may be written on 
<BR>
the horizon, perhaps in the form of impressed strings, like flattened 
<BR>
spaghetti. 
<BR>
<P>Because of this, Lloyd thinks it could be possible to use a black hole as the 
<BR>
ultimate computer. At this black hole limit, it turns out that the time 
<BR>
required to communicate around the hole is exactly the same as the time 
<BR>
needed to flip each bit. &quot;In other words, the black-hole computer is the 
<BR>
ultimate serial computer,&quot; says Lloyd. He believes that this apparent 
<BR>
coincidence hints at another deep link between physics and information. 
<BR>
<P>Ideas for how this black-hole computer would process information are even 
<BR>
vaguer than for the box of gamma rays. The input would be the initial state 
<BR>
of the material, the program would be how that material is forced to collapse 
<BR>
into a black hole. The output would be somehow encoded in the Hawking 
<BR>
radiation, emitted in a rapid blast as the hole evaporates. This is a one-off 
<BR>
computer, exploding with the answer to its calculation. 
<BR>
<P>So here is where Moore's law must end, with a billion-degree laptop or an 
<BR>
exploding submicroscopic black hole. &quot;The truth is we have no notion of how 
<BR>
to attain these ultimate limits,&quot; admits Lloyd. But don't despair--put your 
<BR>
faith in human ingenuity. If the rate of progress doesn't slow, we'll reach 
<BR>
these ultimate physical limits in just two hundred years' time. 
<BR>
&nbsp;
<BR>
<P>&nbsp;
<BR>
<P><P><EM>&gt;From New Scientist magazine, 02 September 2000.
</EM><BR>
<P><P>------------------------------------------------------------------------------
<BR>
<PRE>
--
<P>Subscribe to New Scientist
<P> 
  New Scientist Home _________________________  NEW SCIENTIST Contents page 
New Scientist Jobs Graduate CareersEditorial News Features Opinion Letters 
Feedback The Last Word Back Issues _________________________ WEB ONLY: 
Insight Special Reports Bizarre Science Science in the Bay Area Last Word Q &amp; 
A Archive Keysites Science Books Artspace _________________________  Search 
the site _________________________  Subscribe  
<P><P>© Copyright New Scientist, RBI Limited 2000
 
 
</PRE>
<P><!-- body="end" -->
<HR NOSHADE>
<UL>
<!-- next="start" -->
<LI><STRONG>Next message:</STRONG> <A HREF="3831.html">CYMM: "Mysticism (WAS) E.S.P. in the Turing Test"</A>
<LI><STRONG>Previous message:</STRONG> <A HREF="3829.html">QueeneMUSE@aol.com: "Re: E.S.P. in the Turing Test"</A>
<!-- nextthread="start" -->
<LI><STRONG>Next in thread:</STRONG> <A HREF="3866.html">Adrian Tymes: "Re: The Last Computer"</A>
<LI><STRONG>Reply:</STRONG> <A HREF="3866.html">Adrian Tymes: "Re: The Last Computer"</A>
<!-- reply="end" -->
<LI><STRONG>Messages sorted by:</STRONG> 
<A HREF="date.html#3830">[ date ]</A>
<A HREF="index.html#3830">[ thread ]</A>
<A HREF="subject.html#3830">[ subject ]</A>
<A HREF="author.html#3830">[ author ]</A>
</UL>
<!-- trailer="footer" -->
<HR NOSHADE>
<P>
<SMALL>
<EM>
This archive was generated by <A HREF="http://www.hypermail.org/">hypermail 2b29</A> 
: <EM>Mon Oct 02 2000 - 17:36:50 MDT</EM>
</EM>
</SMALL>
</BODY>
</HTML>
